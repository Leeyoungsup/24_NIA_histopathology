{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import get_rank, init_process_group, destroy_process_group, all_gather, get_world_size\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from conditionDiffusion.unet import Unet\n",
    "from conditionDiffusion.embedding import ConditionalEmbedding\n",
    "from conditionDiffusion.utils import get_named_beta_schedule\n",
    "from conditionDiffusion.diffusion import GaussianDiffusion\n",
    "from conditionDiffusion.Scheduler import GradualWarmupScheduler\n",
    "from PIL import Image\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",5)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "import pytorch_model_summary as tms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['유형1','유형2']\n",
    "params={'image_size':1024,\n",
    "        'lr':1e-5,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'data_path':'../../data/origin_type/BRNT/',\n",
    "        'image_count':5000,\n",
    "        'inch':3,\n",
    "        'modch':64,\n",
    "        'outch':3,\n",
    "        'chmul':[1,2,4,8,16,16,16],\n",
    "        'numres':2,\n",
    "        'dtype':torch.float32,\n",
    "        'cdim':10,\n",
    "        'useconv':False,\n",
    "        'droprate':0.1,\n",
    "        'T':1000,\n",
    "        'w':1.8,\n",
    "        'v':0.3,\n",
    "        'multiplier':2.5,\n",
    "        'threshold':0.1,\n",
    "        'ddim':True,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 14.20it/s]\n",
      "100%|██████████| 3722/3722 [01:15<00:00, 48.98it/s]\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self,parmas, images,label):\n",
    "        \n",
    "        self.images = images\n",
    "        self.args=parmas\n",
    "        self.label=label\n",
    "        \n",
    "    def trans(self,image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index]\n",
    "        label=self.label[index]\n",
    "        image = self.trans(image)\n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "image_label=[]\n",
    "image_path=[]\n",
    "for i in tqdm(range(len(class_list))):\n",
    "    image_list=glob(params['data_path']+class_list[i]+'/*.jpeg')\n",
    "    for j in range(len(image_list)):\n",
    "        image_path.append(image_list[j])\n",
    "        image_label.append(i)\n",
    "        \n",
    "train_images=torch.zeros((len(image_path),params['inch'],params['image_size'],params['image_size']))\n",
    "for i in tqdm(range(len(image_path))):\n",
    "    train_images[i]=trans(Image.open(image_path[i]).convert('RGB').resize((params['image_size'],params['image_size'])))\n",
    "train_dataset=CustomDataset(params,train_images,image_label)\n",
    "dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(in_ch = params['inch'],\n",
    "            mod_ch = params['modch'],\n",
    "            out_ch = params['outch'],\n",
    "            ch_mul = params['chmul'],\n",
    "            num_res_blocks = params['numres'],\n",
    "            cdim = params['cdim'],\n",
    "            use_conv = params['useconv'],\n",
    "            droprate = params['droprate'],\n",
    "            dtype = params['dtype']\n",
    "            ).to(device)\n",
    "cemblayer = ConditionalEmbedding(len(class_list), params['cdim'], params['cdim']).to(device)\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps = params['T'])\n",
    "diffusion = GaussianDiffusion(\n",
    "                    dtype = params['dtype'],\n",
    "                    model = net,\n",
    "                    betas = betas,\n",
    "                    w = params['w'],\n",
    "                    v = params['v'],\n",
    "                    device = device\n",
    "                )\n",
    "optimizer = torch.optim.AdamW(\n",
    "                itertools.chain(\n",
    "                    diffusion.model.parameters(),\n",
    "                    cemblayer.parameters()\n",
    "                ),\n",
    "                lr = params['lr'],\n",
    "                weight_decay = 1e-4\n",
    "            )\n",
    "\n",
    "cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                            optimizer = optimizer,\n",
    "                            T_max = params['epochs']/100,\n",
    "                            eta_min = 0,\n",
    "                            last_epoch = -1\n",
    "                        )\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "                        optimizer = optimizer,\n",
    "                        multiplier = params['multiplier'],\n",
    "                        warm_epoch = params['epochs'] // 10,\n",
    "                        after_scheduler = cosineScheduler,\n",
    "                        last_epoch = 0\n",
    "                    )\n",
    "checkpoint=torch.load(f'../../model/conditionDiff/details/BRNT/ckpt_101_checkpoint.pt',map_location=device)\n",
    "diffusion.model.load_state_dict(checkpoint['net'])\n",
    "cemblayer.load_state_dict(checkpoint['cemblayer'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "warmUpScheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [33:00<00:00,  1.88it/s, epoch=111, loss: =0.0273, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.37e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:25<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [32:53<00:00,  1.89it/s, epoch=112, loss: =0.0246, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.38e-5]\n",
      "100%|██████████| 3722/3722 [33:03<00:00,  1.88it/s, epoch=113, loss: =0.0237, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.4e-5]\n",
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=114, loss: =0.0244, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.41e-5]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=115, loss: =0.0255, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.42e-5]\n",
      "100%|██████████| 3722/3722 [33:19<00:00,  1.86it/s, epoch=116, loss: =0.0238, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [32:52<00:00,  1.89it/s, epoch=117, loss: =0.0236, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.46e-5]\n",
      "100%|██████████| 3722/3722 [32:53<00:00,  1.89it/s, epoch=118, loss: =0.0241, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.47e-5]\n",
      "100%|██████████| 3722/3722 [32:55<00:00,  1.88it/s, epoch=119, loss: =0.0249, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.49e-5]\n",
      "100%|██████████| 3722/3722 [32:53<00:00,  1.89it/s, epoch=120, loss: =0.0233, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.5e-5]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=121, loss: =0.0244, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:30<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [32:51<00:00,  1.89it/s, epoch=122, loss: =0.0233, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=9.76e-6]\n",
      "100%|██████████| 3722/3722 [33:03<00:00,  1.88it/s, epoch=123, loss: =0.0226, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=9.05e-6]\n",
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=124, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=7.94e-6]\n",
      "100%|██████████| 3722/3722 [32:59<00:00,  1.88it/s, epoch=125, loss: =0.0226, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.55e-6]\n",
      "100%|██████████| 3722/3722 [32:55<00:00,  1.88it/s, epoch=126, loss: =0.0228, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5e-6]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=127, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=3.45e-6]\n",
      "100%|██████████| 3722/3722 [32:55<00:00,  1.88it/s, epoch=128, loss: =0.0234, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.06e-6]\n",
      "100%|██████████| 3722/3722 [32:56<00:00,  1.88it/s, epoch=129, loss: =0.0231, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=9.55e-7]\n",
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=130, loss: =0.0234, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.45e-7]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=131, loss: =0.024, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:35<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=132, loss: =0.0225, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [32:56<00:00,  1.88it/s, epoch=133, loss: =0.023, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6] \n",
      "100%|██████████| 3722/3722 [32:56<00:00,  1.88it/s, epoch=134, loss: =0.0235, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=135, loss: =0.0231, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=136, loss: =0.0239, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=137, loss: =0.0243, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [32:56<00:00,  1.88it/s, epoch=138, loss: =0.025, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5] \n",
      "100%|██████████| 3722/3722 [33:01<00:00,  1.88it/s, epoch=139, loss: =0.0239, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:02<00:00,  1.88it/s, epoch=140, loss: =0.0248, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [32:59<00:00,  1.88it/s, epoch=141, loss: =0.0241, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.5e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:30<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [32:56<00:00,  1.88it/s, epoch=142, loss: =0.023, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5] \n",
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=143, loss: =0.0245, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [32:58<00:00,  1.88it/s, epoch=144, loss: =0.0224, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:02<00:00,  1.88it/s, epoch=145, loss: =0.0241, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [32:52<00:00,  1.89it/s, epoch=146, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:01<00:00,  1.88it/s, epoch=147, loss: =0.0246, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [33:11<00:00,  1.87it/s, epoch=148, loss: =0.0232, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [33:09<00:00,  1.87it/s, epoch=149, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [33:32<00:00,  1.85it/s, epoch=150, loss: =0.0222, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:13<00:00,  1.87it/s, epoch=151, loss: =0.0235, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:29<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [33:25<00:00,  1.86it/s, epoch=152, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:23<00:00,  1.86it/s, epoch=153, loss: =0.023, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6] \n",
      "100%|██████████| 3722/3722 [33:20<00:00,  1.86it/s, epoch=154, loss: =0.0236, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [33:44<00:00,  1.84it/s, epoch=155, loss: =0.0228, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [33:14<00:00,  1.87it/s, epoch=156, loss: =0.0245, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:16<00:00,  1.86it/s, epoch=157, loss: =0.0234, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [33:08<00:00,  1.87it/s, epoch=158, loss: =0.0234, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:10<00:00,  1.87it/s, epoch=159, loss: =0.0225, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:09<00:00,  1.87it/s, epoch=160, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [33:11<00:00,  1.87it/s, epoch=161, loss: =0.0241, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.5e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:30<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [33:12<00:00,  1.87it/s, epoch=162, loss: =0.0238, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [33:09<00:00,  1.87it/s, epoch=163, loss: =0.0218, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:04<00:00,  1.88it/s, epoch=164, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:10<00:00,  1.87it/s, epoch=165, loss: =0.0232, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5] \n",
      "100%|██████████| 3722/3722 [33:02<00:00,  1.88it/s, epoch=166, loss: =0.0236, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:05<00:00,  1.87it/s, epoch=167, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [33:13<00:00,  1.87it/s, epoch=168, loss: =0.0223, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [33:25<00:00,  1.86it/s, epoch=169, loss: =0.0221, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [33:28<00:00,  1.85it/s, epoch=170, loss: =0.0223, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:26<00:00,  1.85it/s, epoch=171, loss: =0.0233, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:33<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [33:17<00:00,  1.86it/s, epoch=172, loss: =0.0214, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:22<00:00,  1.86it/s, epoch=173, loss: =0.0234, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [33:24<00:00,  1.86it/s, epoch=174, loss: =0.024, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6] \n",
      "100%|██████████| 3722/3722 [33:28<00:00,  1.85it/s, epoch=175, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [33:15<00:00,  1.87it/s, epoch=176, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:15<00:00,  1.87it/s, epoch=177, loss: =0.0223, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [33:12<00:00,  1.87it/s, epoch=178, loss: =0.0238, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:08<00:00,  1.87it/s, epoch=179, loss: =0.0224, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:06<00:00,  1.87it/s, epoch=180, loss: =0.0231, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [33:20<00:00,  1.86it/s, epoch=181, loss: =0.022, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.5e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:43<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [33:29<00:00,  1.85it/s, epoch=182, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5] \n",
      "100%|██████████| 3722/3722 [33:27<00:00,  1.85it/s, epoch=183, loss: =0.0222, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:12<00:00,  1.87it/s, epoch=184, loss: =0.0228, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:02<00:00,  1.88it/s, epoch=185, loss: =0.0233, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [33:13<00:00,  1.87it/s, epoch=186, loss: =0.0224, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:33<00:00,  1.85it/s, epoch=187, loss: =0.0223, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [32:59<00:00,  1.88it/s, epoch=188, loss: =0.024, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6] \n",
      "100%|██████████| 3722/3722 [32:54<00:00,  1.89it/s, epoch=189, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [32:54<00:00,  1.89it/s, epoch=190, loss: =0.022, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7] \n",
      "100%|██████████| 3722/3722 [33:12<00:00,  1.87it/s, epoch=191, loss: =0.0212, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:13<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [33:08<00:00,  1.87it/s, epoch=192, loss: =0.0216, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:14<00:00,  1.87it/s, epoch=193, loss: =0.0212, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [33:11<00:00,  1.87it/s, epoch=194, loss: =0.0219, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [33:11<00:00,  1.87it/s, epoch=195, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [33:12<00:00,  1.87it/s, epoch=196, loss: =0.0245, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:17<00:00,  1.86it/s, epoch=197, loss: =0.0223, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [33:25<00:00,  1.86it/s, epoch=198, loss: =0.0221, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:22<00:00,  1.86it/s, epoch=199, loss: =0.0221, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:28<00:00,  1.85it/s, epoch=200, loss: =0.0221, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [33:23<00:00,  1.86it/s, epoch=201, loss: =0.0219, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.5e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [32:41<00:00,  1.90it/s, epoch=202, loss: =0.0228, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [33:26<00:00,  1.86it/s, epoch=203, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [33:34<00:00,  1.85it/s, epoch=204, loss: =0.0219, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [33:17<00:00,  1.86it/s, epoch=205, loss: =0.0216, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [32:44<00:00,  1.89it/s, epoch=206, loss: =0.0227, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [33:46<00:00,  1.84it/s, epoch=207, loss: =0.0216, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [33:06<00:00,  1.87it/s, epoch=208, loss: =0.0214, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [33:02<00:00,  1.88it/s, epoch=209, loss: =0.0205, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [33:26<00:00,  1.85it/s, epoch=210, loss: =0.0224, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:22<00:00,  1.86it/s, epoch=211, loss: =0.0218, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:09<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=212, loss: =0.0219, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=6.12e-7]\n",
      "100%|██████████| 3722/3722 [33:11<00:00,  1.87it/s, epoch=213, loss: =0.0215, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.39e-6]\n",
      "100%|██████████| 3722/3722 [32:57<00:00,  1.88it/s, epoch=214, loss: =0.0218, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=5.15e-6]\n",
      "100%|██████████| 3722/3722 [32:40<00:00,  1.90it/s, epoch=215, loss: =0.0207, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=8.64e-6]\n",
      "100%|██████████| 3722/3722 [32:37<00:00,  1.90it/s, epoch=216, loss: =0.0214, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.25e-5]\n",
      "100%|██████████| 3722/3722 [32:37<00:00,  1.90it/s, epoch=217, loss: =0.0222, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.64e-5]\n",
      "100%|██████████| 3722/3722 [32:38<00:00,  1.90it/s, epoch=218, loss: =0.0226, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 3722/3722 [32:45<00:00,  1.89it/s, epoch=219, loss: =0.0229, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 3722/3722 [32:40<00:00,  1.90it/s, epoch=220, loss: =0.0233, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.44e-5]\n",
      "100%|██████████| 3722/3722 [32:42<00:00,  1.90it/s, epoch=221, loss: =0.0212, batch per device: =1, img shape: =torch.Size([3, 1024, 1024]), LR=2.5e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:45<00:29,  2.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m genshape \u001b[38;5;241m=\u001b[39m (each_device_batch , \u001b[38;5;241m3\u001b[39m, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddim\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 45\u001b[0m     generated \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcemb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     generated \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39msample(genshape, cemb \u001b[38;5;241m=\u001b[39m cemb)\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/2024_NIA_histopathology/code/24_NIA_histopathology/conditionDiffusion/diffusion.py:239\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample\u001b[0;34m(self, shape, num_steps, eta, select, **model_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m             prevt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(tlist, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \n\u001b[0;32m--> 239\u001b[0m         x_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_p_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    241\u001b[0m x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(x_t, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/2024_NIA_histopathology/code/24_NIA_histopathology/conditionDiffusion/diffusion.py:207\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_p_sample\u001b[0;34m(self, x_t, t, prevt, eta, **model_kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m B, C \u001b[38;5;241m=\u001b[39m x_t\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (B,), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize of t is not batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 207\u001b[0m mean, var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_p_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(mean)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan in tensor mean when t = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(var)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan in tensor var when t = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/2024_NIA_histopathology/code/24_NIA_histopathology/conditionDiffusion/diffusion.py:184\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_p_mean_variance\u001b[0;34m(self, x_t, t, prevt, eta, **model_kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m pred_eps_cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x_t, t, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    183\u001b[0m model_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcemb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(cemb_shape, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 184\u001b[0m pred_eps_uncond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m pred_eps \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw) \u001b[38;5;241m*\u001b[39m pred_eps_cond \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m*\u001b[39m pred_eps_uncond\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(x_t)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan in tensor x_t when t = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/2024_NIA_histopathology/code/24_NIA_histopathology/conditionDiffusion/unet.py:251\u001b[0m, in \u001b[0;36mUnet.forward\u001b[0;34m(self, x, t, cemb)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupblocks:\n\u001b[1;32m    250\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h, hs\u001b[38;5;241m.\u001b[39mpop()], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(h)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/2024_NIA_histopathology/code/24_NIA_histopathology/conditionDiffusion/unet.py:71\u001b[0m, in \u001b[0;36mEmbedSequential.forward\u001b[0;34m(self, x, temb, cemb)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, EmbedBlock):\n\u001b[0;32m---> 71\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/2024_NIA_histopathology/code/24_NIA_histopathology/conditionDiffusion/unet.py:112\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x, temb, cemb)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:torch\u001b[38;5;241m.\u001b[39mTensor, temb:torch\u001b[38;5;241m.\u001b[39mTensor, cemb:torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    111\u001b[0m     latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_1(x)\n\u001b[0;32m--> 112\u001b[0m     latent \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemb_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m)\u001b[49m[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    113\u001b[0m     latent \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcemb_proj(cemb)[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    114\u001b[0m     latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_2(latent)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/activation.py:393\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/functional.py:2072\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   2071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epc in range(110,params['epochs']):\n",
    "    diffusion.model.train()\n",
    "    cemblayer.train()\n",
    "    total_loss=0\n",
    "    steps=0\n",
    "    with tqdm(dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "        for img, lab in tqdmDataLoader:\n",
    "            b = img.shape[0]\n",
    "            optimizer.zero_grad()\n",
    "            x_0 = img.to(device)\n",
    "            lab = lab.to(device)\n",
    "            cemb = cemblayer(lab)\n",
    "            cemb[np.where(np.random.rand(b)<params['threshold'])] = 0\n",
    "            loss = diffusion.trainloss(x_0, cemb = cemb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps+=1\n",
    "            total_loss+=loss.item()\n",
    "            tqdmDataLoader.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"epoch\": epc + 1,\n",
    "                    \"loss: \": total_loss/steps,\n",
    "                    \"batch per device: \":x_0.shape[0],\n",
    "                    \"img shape: \": x_0.shape[1:],\n",
    "                    \"LR\": optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
    "                }\n",
    "            )\n",
    "    warmUpScheduler.step()\n",
    "    if (epc) % 10 == 0:\n",
    "        diffusion.model.eval()\n",
    "        cemblayer.eval()\n",
    "        # generating samples\n",
    "        # The model generate 80 pictures(8 per row) each time\n",
    "        # pictures of same row belong to the same class\n",
    "        all_samples = []\n",
    "        each_device_batch =10\n",
    "        with torch.no_grad():\n",
    "            lab = torch.ones(len(class_list), each_device_batch // len(class_list)).type(torch.long) \\\n",
    "            * torch.arange(start = 0, end = len(class_list)).reshape(-1, 1)\n",
    "            lab = lab.reshape(-1, 1).squeeze()\n",
    "            lab = lab.to(device)\n",
    "            cemb = cemblayer(lab)\n",
    "            genshape = (each_device_batch , 3, params['image_size'], params['image_size'])\n",
    "            if params['ddim']:\n",
    "                generated = diffusion.ddim_sample(genshape, 50, 0, 'linear', cemb = cemb)\n",
    "            else:\n",
    "                generated = diffusion.sample(genshape, cemb = cemb)\n",
    "            img = transback(generated)\n",
    "            img = img.reshape(len(class_list), each_device_batch // len(class_list), 3, params['image_size'], params['image_size']).contiguous()\n",
    "            all_samples.append(img)\n",
    "            samples = torch.concat(all_samples, dim = 1).reshape(each_device_batch, 3,params['image_size'], params['image_size'])\n",
    "\n",
    "        save_image(samples,f'../../result/Detail/BRNT/generated_{epc+1}_pict.png', nrow = each_device_batch // len(class_list))\n",
    "        # save checkpoints\n",
    "        checkpoint = {\n",
    "                            'net':diffusion.model.state_dict(),\n",
    "                            'cemblayer':cemblayer.state_dict(),\n",
    "                            'optimizer':optimizer.state_dict(),\n",
    "                            'scheduler':warmUpScheduler.state_dict()\n",
    "                        }\n",
    "        torch.save(checkpoint, f'../../model/conditionDiff/details/BRNT/ckpt_{epc+1}_checkpoint.pt')\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
