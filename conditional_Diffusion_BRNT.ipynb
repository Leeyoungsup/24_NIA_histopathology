{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import get_rank, init_process_group, destroy_process_group, all_gather, get_world_size\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from conditionDiffusion.unet import Unet\n",
    "from conditionDiffusion.embedding import ConditionalEmbedding\n",
    "from conditionDiffusion.utils import get_named_beta_schedule\n",
    "from conditionDiffusion.diffusion import GaussianDiffusion\n",
    "from conditionDiffusion.Scheduler import GradualWarmupScheduler\n",
    "from PIL import Image\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",4)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "import pytorch_model_summary as tms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['유형1','유형2']\n",
    "params={'image_size':1024,\n",
    "        'lr':1e-5,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':4,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'data_path':'../../data/origin_type/BRNT/',\n",
    "        'image_count':5000,\n",
    "        'inch':3,\n",
    "        'modch':32,\n",
    "        'outch':3,\n",
    "        'chmul':[1,2,4,8,16,32,32],\n",
    "        'numres':2,\n",
    "        'dtype':torch.float32,\n",
    "        'cdim':10,\n",
    "        'useconv':False,\n",
    "        'droprate':0.1,\n",
    "        'T':1000,\n",
    "        'w':1.8,\n",
    "        'v':0.3,\n",
    "        'multiplier':2.5,\n",
    "        'threshold':0.1,\n",
    "        'ddim':True,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.30it/s]\n",
      " 15%|█▍        | 551/3722 [01:48<05:06, 10.34it/s]"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self,parmas, images,label):\n",
    "        \n",
    "        self.images = images\n",
    "        self.args=parmas\n",
    "        self.label=label\n",
    "        \n",
    "    def trans(self,image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index]\n",
    "        label=self.label[index]\n",
    "        image = self.trans(image)\n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "image_label=[]\n",
    "image_path=[]\n",
    "for i in tqdm(range(len(class_list))):\n",
    "    image_list=glob(params['data_path']+class_list[i]+'/*.jpeg')\n",
    "    for j in range(len(image_list)):\n",
    "        image_path.append(image_list[j])\n",
    "        image_label.append(i)\n",
    "        \n",
    "train_images=torch.zeros((len(image_path),params['inch'],params['image_size'],params['image_size']))\n",
    "for i in tqdm(range(len(image_path))):\n",
    "    train_images[i]=trans(Image.open(image_path[i]).convert('RGB').resize((params['image_size'],params['image_size'])))\n",
    "train_dataset=CustomDataset(params,train_images,image_label)\n",
    "dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     36\u001b[0m warmUpScheduler \u001b[38;5;241m=\u001b[39m GradualWarmupScheduler(\n\u001b[1;32m     37\u001b[0m                         optimizer \u001b[38;5;241m=\u001b[39m optimizer,\n\u001b[1;32m     38\u001b[0m                         multiplier \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiplier\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         last_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     42\u001b[0m                     )\n\u001b[1;32m     43\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     44\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m'\u001b[39m:diffusion\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     45\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcemblayer\u001b[39m\u001b[38;5;124m'\u001b[39m:cemblayer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     46\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m:optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     47\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m'\u001b[39m:warmUpScheduler\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m     48\u001b[0m                         }\n\u001b[0;32m---> 49\u001b[0m \u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../model/conditionDiff/details/BRNT/ckpt_111_checkpoint.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "net = Unet(in_ch = params['inch'],\n",
    "            mod_ch = params['modch'],\n",
    "            out_ch = params['outch'],\n",
    "            ch_mul = params['chmul'],\n",
    "            num_res_blocks = params['numres'],\n",
    "            cdim = params['cdim'],\n",
    "            use_conv = params['useconv'],\n",
    "            droprate = params['droprate'],\n",
    "            dtype = params['dtype']\n",
    "            ).to(device)\n",
    "cemblayer = ConditionalEmbedding(len(class_list), params['cdim'], params['cdim']).to(device)\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps = params['T'])\n",
    "diffusion = GaussianDiffusion(\n",
    "                    dtype = params['dtype'],\n",
    "                    model = net,\n",
    "                    betas = betas,\n",
    "                    w = params['w'],\n",
    "                    v = params['v'],\n",
    "                    device = device\n",
    "                )\n",
    "optimizer = torch.optim.AdamW(\n",
    "                itertools.chain(\n",
    "                    diffusion.model.parameters(),\n",
    "                    cemblayer.parameters()\n",
    "                ),\n",
    "                lr = params['lr'],\n",
    "                weight_decay = 1e-4\n",
    "            )\n",
    "\n",
    "cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                            optimizer = optimizer,\n",
    "                            T_max = params['epochs']/100,\n",
    "                            eta_min = 0,\n",
    "                            last_epoch = -1\n",
    "                        )\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "                        optimizer = optimizer,\n",
    "                        multiplier = params['multiplier'],\n",
    "                        warm_epoch = params['epochs'] // 10,\n",
    "                        after_scheduler = cosineScheduler,\n",
    "                        last_epoch = 0\n",
    "                    )\n",
    "checkpoint=torch.load(f'../../model/conditionDiff/details/BRNT/ckpt_111_checkpoint.pt')\n",
    "diffusion.model.load_state_dict(checkpoint['net'])\n",
    "cemblayer.load_state_dict(checkpoint['cemblayer'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "warmUpScheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:30<00:00,  1.58s/it, epoch=11, loss: =0.419, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:32<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:29<00:00,  1.58s/it, epoch=12, loss: =0.135, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.01e-5]\n",
      "100%|██████████| 931/931 [24:30<00:00,  1.58s/it, epoch=13, loss: =0.0923, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.03e-5]\n",
      "100%|██████████| 931/931 [24:33<00:00,  1.58s/it, epoch=14, loss: =0.078, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.04e-5] \n",
      "100%|██████████| 931/931 [24:43<00:00,  1.59s/it, epoch=15, loss: =0.0631, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.06e-5]\n",
      "100%|██████████| 931/931 [24:34<00:00,  1.58s/it, epoch=16, loss: =0.056, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.08e-5] \n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=17, loss: =0.05, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.09e-5]  \n",
      "100%|██████████| 931/931 [24:36<00:00,  1.59s/it, epoch=18, loss: =0.0451, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.11e-5]\n",
      "100%|██████████| 931/931 [24:35<00:00,  1.59s/it, epoch=19, loss: =0.0443, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.12e-5]\n",
      "100%|██████████| 931/931 [25:09<00:00,  1.62s/it, epoch=20, loss: =0.0407, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.14e-5]\n",
      "100%|██████████| 931/931 [25:00<00:00,  1.61s/it, epoch=21, loss: =0.0392, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.15e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:17<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:51<00:00,  1.60s/it, epoch=22, loss: =0.0365, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.17e-5]\n",
      "100%|██████████| 931/931 [24:39<00:00,  1.59s/it, epoch=23, loss: =0.0361, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.18e-5]\n",
      "100%|██████████| 931/931 [24:45<00:00,  1.60s/it, epoch=24, loss: =0.0345, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.2e-5]\n",
      "100%|██████████| 931/931 [24:50<00:00,  1.60s/it, epoch=25, loss: =0.0361, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.21e-5]\n",
      "100%|██████████| 931/931 [24:52<00:00,  1.60s/it, epoch=26, loss: =0.0337, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.23e-5] \n",
      "100%|██████████| 931/931 [24:39<00:00,  1.59s/it, epoch=27, loss: =0.0315, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.24e-5]\n",
      "100%|██████████| 931/931 [24:32<00:00,  1.58s/it, epoch=28, loss: =0.0339, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.26e-5]\n",
      "100%|██████████| 931/931 [24:51<00:00,  1.60s/it, epoch=29, loss: =0.0332, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.27e-5]\n",
      "100%|██████████| 931/931 [24:39<00:00,  1.59s/it, epoch=30, loss: =0.0304, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.29e-5]\n",
      "100%|██████████| 931/931 [24:26<00:00,  1.58s/it, epoch=31, loss: =0.0325, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.3e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:48<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:48<00:00,  1.60s/it, epoch=32, loss: =0.0298, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.32e-5]\n",
      "100%|██████████| 931/931 [24:31<00:00,  1.58s/it, epoch=33, loss: =0.031, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.33e-5] \n",
      "100%|██████████| 931/931 [24:39<00:00,  1.59s/it, epoch=34, loss: =0.0291, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.35e-5]\n",
      "100%|██████████| 931/931 [24:20<00:00,  1.57s/it, epoch=35, loss: =0.0282, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.36e-5]\n",
      "100%|██████████| 931/931 [24:40<00:00,  1.59s/it, epoch=36, loss: =0.0302, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.38e-5]\n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=37, loss: =0.027, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.39e-5] \n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=38, loss: =0.0282, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.41e-5]\n",
      "100%|██████████| 931/931 [24:32<00:00,  1.58s/it, epoch=39, loss: =0.0292, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.42e-5]\n",
      "100%|██████████| 931/931 [24:33<00:00,  1.58s/it, epoch=40, loss: =0.028, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.44e-5] \n",
      "100%|██████████| 931/931 [24:42<00:00,  1.59s/it, epoch=41, loss: =0.0268, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.45e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:49<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:41<00:00,  1.59s/it, epoch=42, loss: =0.0291, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.47e-5]\n",
      "100%|██████████| 931/931 [24:40<00:00,  1.59s/it, epoch=43, loss: =0.0287, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.48e-5]\n",
      "100%|██████████| 931/931 [24:48<00:00,  1.60s/it, epoch=44, loss: =0.0265, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.5e-5]\n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=45, loss: =0.025, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.51e-5] \n",
      "100%|██████████| 931/931 [24:45<00:00,  1.60s/it, epoch=46, loss: =0.028, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.52e-5] \n",
      "100%|██████████| 931/931 [24:28<00:00,  1.58s/it, epoch=47, loss: =0.0272, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.54e-5]\n",
      "100%|██████████| 931/931 [24:56<00:00,  1.61s/it, epoch=48, loss: =0.0279, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.56e-5]\n",
      "100%|██████████| 931/931 [24:56<00:00,  1.61s/it, epoch=49, loss: =0.0271, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.57e-5]\n",
      "100%|██████████| 931/931 [25:01<00:00,  1.61s/it, epoch=50, loss: =0.0264, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.59e-5]\n",
      "100%|██████████| 931/931 [24:48<00:00,  1.60s/it, epoch=51, loss: =0.0275, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.6e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:46<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:49<00:00,  1.60s/it, epoch=52, loss: =0.0259, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.62e-5]\n",
      "100%|██████████| 931/931 [24:38<00:00,  1.59s/it, epoch=53, loss: =0.0277, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.63e-5]\n",
      "100%|██████████| 931/931 [24:41<00:00,  1.59s/it, epoch=54, loss: =0.0266, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.65e-5]\n",
      "100%|██████████| 931/931 [24:48<00:00,  1.60s/it, epoch=55, loss: =0.0261, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.66e-5]\n",
      "100%|██████████| 931/931 [24:36<00:00,  1.59s/it, epoch=56, loss: =0.0252, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.68e-5]\n",
      "100%|██████████| 931/931 [24:41<00:00,  1.59s/it, epoch=57, loss: =0.0271, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.69e-5]\n",
      "100%|██████████| 931/931 [24:31<00:00,  1.58s/it, epoch=58, loss: =0.0261, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.71e-5]\n",
      "100%|██████████| 931/931 [24:36<00:00,  1.59s/it, epoch=59, loss: =0.0268, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.72e-5]\n",
      "100%|██████████| 931/931 [24:49<00:00,  1.60s/it, epoch=60, loss: =0.0252, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.74e-5]\n",
      "100%|██████████| 931/931 [24:22<00:00,  1.57s/it, epoch=61, loss: =0.0246, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.75e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:50<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:42<00:00,  1.59s/it, epoch=62, loss: =0.0262, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.77e-5]\n",
      "100%|██████████| 931/931 [24:41<00:00,  1.59s/it, epoch=63, loss: =0.0265, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.78e-5]\n",
      "100%|██████████| 931/931 [24:53<00:00,  1.60s/it, epoch=64, loss: =0.0247, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.79e-5]\n",
      "100%|██████████| 931/931 [24:33<00:00,  1.58s/it, epoch=65, loss: =0.0259, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.81e-5]\n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=66, loss: =0.0253, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.82e-5]\n",
      "100%|██████████| 931/931 [24:27<00:00,  1.58s/it, epoch=67, loss: =0.024, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.84e-5] \n",
      "100%|██████████| 931/931 [24:33<00:00,  1.58s/it, epoch=68, loss: =0.0238, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.86e-5]\n",
      "100%|██████████| 931/931 [24:35<00:00,  1.58s/it, epoch=69, loss: =0.0227, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.87e-5]\n",
      "100%|██████████| 931/931 [24:34<00:00,  1.58s/it, epoch=70, loss: =0.0261, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.89e-5]\n",
      "100%|██████████| 931/931 [24:34<00:00,  1.58s/it, epoch=71, loss: =0.0245, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.9e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:48<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:31<00:00,  1.58s/it, epoch=72, loss: =0.0273, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.92e-5]\n",
      "100%|██████████| 931/931 [24:51<00:00,  1.60s/it, epoch=73, loss: =0.0247, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.93e-5]\n",
      "100%|██████████| 931/931 [24:26<00:00,  1.58s/it, epoch=74, loss: =0.0242, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.94e-5]\n",
      "100%|██████████| 931/931 [24:47<00:00,  1.60s/it, epoch=75, loss: =0.0256, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.96e-5]\n",
      "100%|██████████| 931/931 [24:40<00:00,  1.59s/it, epoch=76, loss: =0.0249, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.98e-5]\n",
      "100%|██████████| 931/931 [24:36<00:00,  1.59s/it, epoch=77, loss: =0.0262, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=1.99e-5]\n",
      "100%|██████████| 931/931 [24:23<00:00,  1.57s/it, epoch=78, loss: =0.0253, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2e-5]\n",
      "100%|██████████| 931/931 [24:28<00:00,  1.58s/it, epoch=79, loss: =0.0256, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.02e-5]\n",
      "100%|██████████| 931/931 [24:28<00:00,  1.58s/it, epoch=80, loss: =0.025, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.04e-5] \n",
      "100%|██████████| 931/931 [24:40<00:00,  1.59s/it, epoch=81, loss: =0.0242, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.05e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:51<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:38<00:00,  1.59s/it, epoch=82, loss: =0.0261, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.07e-5]\n",
      "100%|██████████| 931/931 [24:36<00:00,  1.59s/it, epoch=83, loss: =0.0247, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.08e-5]\n",
      "100%|██████████| 931/931 [24:35<00:00,  1.58s/it, epoch=84, loss: =0.0235, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.09e-5]\n",
      "100%|██████████| 931/931 [24:41<00:00,  1.59s/it, epoch=85, loss: =0.0247, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.11e-5]\n",
      "100%|██████████| 931/931 [24:43<00:00,  1.59s/it, epoch=86, loss: =0.025, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.13e-5] \n",
      "100%|██████████| 931/931 [24:33<00:00,  1.58s/it, epoch=87, loss: =0.0256, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.14e-5]\n",
      "100%|██████████| 931/931 [24:31<00:00,  1.58s/it, epoch=88, loss: =0.0254, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.16e-5]\n",
      "100%|██████████| 931/931 [24:31<00:00,  1.58s/it, epoch=89, loss: =0.0232, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.17e-5]\n",
      "100%|██████████| 931/931 [24:39<00:00,  1.59s/it, epoch=90, loss: =0.0252, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.19e-5]\n",
      "100%|██████████| 931/931 [24:35<00:00,  1.58s/it, epoch=91, loss: =0.0234, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.2e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:50<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [24:57<00:00,  1.61s/it, epoch=92, loss: =0.0257, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.21e-5]\n",
      "100%|██████████| 931/931 [24:20<00:00,  1.57s/it, epoch=93, loss: =0.0242, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.23e-5]\n",
      "100%|██████████| 931/931 [24:47<00:00,  1.60s/it, epoch=94, loss: =0.0267, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.25e-5]\n",
      "100%|██████████| 931/931 [24:38<00:00,  1.59s/it, epoch=95, loss: =0.0234, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.26e-5]\n",
      "100%|██████████| 931/931 [24:48<00:00,  1.60s/it, epoch=96, loss: =0.0245, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.28e-5]\n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=97, loss: =0.0237, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.29e-5]\n",
      "100%|██████████| 931/931 [24:53<00:00,  1.60s/it, epoch=98, loss: =0.0247, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.3e-5]\n",
      "100%|██████████| 931/931 [24:41<00:00,  1.59s/it, epoch=99, loss: =0.0244, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.32e-5]\n",
      "100%|██████████| 931/931 [24:40<00:00,  1.59s/it, epoch=100, loss: =0.0227, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.34e-5]\n",
      "100%|██████████| 931/931 [24:37<00:00,  1.59s/it, epoch=101, loss: =0.0232, batch per device: =2, img shape: =torch.Size([3, 1024, 1024]), LR=2.35e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:48<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    }
   ],
   "source": [
    "for epc in range(110,params['epochs']):\n",
    "    diffusion.model.train()\n",
    "    cemblayer.train()\n",
    "    total_loss=0\n",
    "    steps=0\n",
    "    with tqdm(dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "        for img, lab in tqdmDataLoader:\n",
    "            b = img.shape[0]\n",
    "            optimizer.zero_grad()\n",
    "            x_0 = img.to(device)\n",
    "            lab = lab.to(device)\n",
    "            cemb = cemblayer(lab)\n",
    "            cemb[np.where(np.random.rand(b)<params['threshold'])] = 0\n",
    "            loss = diffusion.trainloss(x_0, cemb = cemb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps+=1\n",
    "            total_loss+=loss.item()\n",
    "            tqdmDataLoader.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"epoch\": epc + 1,\n",
    "                    \"loss: \": total_loss/steps,\n",
    "                    \"batch per device: \":x_0.shape[0],\n",
    "                    \"img shape: \": x_0.shape[1:],\n",
    "                    \"LR\": optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
    "                }\n",
    "            )\n",
    "    warmUpScheduler.step()\n",
    "    if (epc) % 10 == 0:\n",
    "        diffusion.model.eval()\n",
    "        cemblayer.eval()\n",
    "        # generating samples\n",
    "        # The model generate 80 pictures(8 per row) each time\n",
    "        # pictures of same row belong to the same class\n",
    "        all_samples = []\n",
    "        each_device_batch =10\n",
    "        with torch.no_grad():\n",
    "            lab = torch.ones(len(class_list), each_device_batch // len(class_list)).type(torch.long) \\\n",
    "            * torch.arange(start = 0, end = len(class_list)).reshape(-1, 1)\n",
    "            lab = lab.reshape(-1, 1).squeeze()\n",
    "            lab = lab.to(device)\n",
    "            cemb = cemblayer(lab)\n",
    "            genshape = (each_device_batch , 3, params['image_size'], params['image_size'])\n",
    "            if params['ddim']:\n",
    "                generated = diffusion.ddim_sample(genshape, 50, 0, 'linear', cemb = cemb)\n",
    "            else:\n",
    "                generated = diffusion.sample(genshape, cemb = cemb)\n",
    "            img = transback(generated)\n",
    "            img = img.reshape(len(class_list), each_device_batch // len(class_list), 3, params['image_size'], params['image_size']).contiguous()\n",
    "            all_samples.append(img)\n",
    "            samples = torch.concat(all_samples, dim = 1).reshape(each_device_batch, 3,params['image_size'], params['image_size'])\n",
    "\n",
    "        save_image(samples,f'../../result/Detail/BRNT/generated_{epc+1}_pict.png', nrow = each_device_batch // len(class_list))\n",
    "        # save checkpoints\n",
    "        checkpoint = {\n",
    "                            'net':diffusion.model.state_dict(),\n",
    "                            'cemblayer':cemblayer.state_dict(),\n",
    "                            'optimizer':optimizer.state_dict(),\n",
    "                            'scheduler':warmUpScheduler.state_dict()\n",
    "                        }\n",
    "        torch.save(checkpoint, f'../../model/conditionDiff/details/BRNT/ckpt_{epc+1}_checkpoint.pt')\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
