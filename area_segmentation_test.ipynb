{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm import create_model\n",
    "import cv2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=1\n",
    "img_size=1024\n",
    "class_list=['NT_stroma','NT_epithelial',\n",
    " 'NT_immune',\n",
    " 'Tumor',]\n",
    "tf = ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "        \n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 708/708 [01:55<00:00,  6.13it/s]\n",
      "100%|██████████| 177/177 [00:32<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "img_path='../../data/area_segmentation/_STIN/image/'\n",
    "img_list=glob(img_path+'*.jpeg')\n",
    "mask_list=[i.replace('/image','/mask/npy') for i in img_list]\n",
    "mask_list=[i.replace('.jpeg','.npy') for i in mask_list]\n",
    "train_img_list,test_img_list,train_mask_list,test_mask_list=train_test_split(img_list,mask_list,test_size=0.2,random_state=42)\n",
    "\n",
    "test_image=torch.zeros((len(test_img_list),3,img_size,img_size))\n",
    "test_mask=torch.zeros((len(test_img_list),len(class_list),img_size,img_size),dtype=torch.float32)    \n",
    "train_image=torch.zeros((len(train_img_list),3,img_size,img_size))\n",
    "train_mask=torch.zeros((len(train_img_list),len(class_list),img_size,img_size),dtype=torch.float32)\n",
    "for i in tqdm(range(len(train_img_list))):\n",
    "    train_image[i] = tf(Image.open(train_img_list[i]))\n",
    "    np_mask=tf(np.load(train_mask_list[i])/255)\n",
    "    train_mask[i]=np_mask\n",
    "for i in tqdm(range(len(test_img_list))):\n",
    "    test_image[i] = tf(Image.open(test_img_list[i]))\n",
    "    np_mask=tf(np.load(test_mask_list[i])/255)\n",
    "    test_mask[i]=np_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        \n",
    "    def trans(self,image,label):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            label = transform(label)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            label = transform(label)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path,label_path = self.trans(self.img_path[idx],self.label[idx])\n",
    "\n",
    "        return image_path, label_path\n",
    "    \n",
    "train_dataset = CustomDataset(train_image, train_mask)\n",
    "\n",
    "test_dataset = CustomDataset(test_image, test_mask)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "UnetPlusPlus                                            [2, 4, 1024, 1024]        --\n",
       "├─EfficientNetEncoder: 1-1                              [2, 3, 1024, 1024]        1,643,520\n",
       "│    └─Conv2dStaticSamePadding: 2-1                     [2, 64, 512, 512]         1,728\n",
       "│    │    └─ZeroPad2d: 3-1                              [2, 3, 1025, 1025]        --\n",
       "│    └─BatchNorm2d: 2-2                                 [2, 64, 512, 512]         128\n",
       "│    └─MemoryEfficientSwish: 2-3                        [2, 64, 512, 512]         --\n",
       "│    └─ModuleList: 2-4                                  --                        --\n",
       "│    │    └─MBConvBlock: 3-2                            [2, 32, 512, 512]         4,944\n",
       "│    │    └─MBConvBlock: 3-3                            [2, 32, 512, 512]         1,992\n",
       "│    │    └─MBConvBlock: 3-4                            [2, 32, 512, 512]         1,992\n",
       "│    │    └─MBConvBlock: 3-5                            [2, 32, 512, 512]         1,992\n",
       "│    │    └─MBConvBlock: 3-6                            [2, 48, 256, 256]         21,224\n",
       "│    │    └─MBConvBlock: 3-7                            [2, 48, 256, 256]         38,700\n",
       "│    │    └─MBConvBlock: 3-8                            [2, 48, 256, 256]         38,700\n",
       "│    │    └─MBConvBlock: 3-9                            [2, 48, 256, 256]         38,700\n",
       "│    │    └─MBConvBlock: 3-10                           [2, 48, 256, 256]         38,700\n",
       "│    │    └─MBConvBlock: 3-11                           [2, 48, 256, 256]         38,700\n",
       "│    │    └─MBConvBlock: 3-12                           [2, 48, 256, 256]         38,700\n",
       "│    │    └─MBConvBlock: 3-13                           [2, 80, 128, 128]         52,588\n",
       "│    │    └─MBConvBlock: 3-14                           [2, 80, 128, 128]         110,580\n",
       "│    │    └─MBConvBlock: 3-15                           [2, 80, 128, 128]         110,580\n",
       "│    │    └─MBConvBlock: 3-16                           [2, 80, 128, 128]         110,580\n",
       "│    │    └─MBConvBlock: 3-17                           [2, 80, 128, 128]         110,580\n",
       "│    │    └─MBConvBlock: 3-18                           [2, 80, 128, 128]         110,580\n",
       "│    │    └─MBConvBlock: 3-19                           [2, 80, 128, 128]         110,580\n",
       "│    │    └─MBConvBlock: 3-20                           [2, 160, 64, 64]          141,460\n",
       "│    │    └─MBConvBlock: 3-21                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-22                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-23                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-24                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-25                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-26                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-27                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-28                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-29                           [2, 160, 64, 64]          397,800\n",
       "│    │    └─MBConvBlock: 3-30                           [2, 224, 64, 64]          474,728\n",
       "│    │    └─MBConvBlock: 3-31                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-32                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-33                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-34                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-35                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-36                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-37                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-38                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-39                           [2, 224, 64, 64]          793,464\n",
       "│    │    └─MBConvBlock: 3-40                           [2, 384, 32, 32]          1,008,824\n",
       "│    │    └─MBConvBlock: 3-41                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-42                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-43                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-44                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-45                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-46                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-47                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-48                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-49                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-50                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-51                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-52                           [2, 384, 32, 32]          2,281,824\n",
       "│    │    └─MBConvBlock: 3-53                           [2, 640, 32, 32]          2,835,296\n",
       "│    │    └─MBConvBlock: 3-54                           [2, 640, 32, 32]          6,199,200\n",
       "│    │    └─MBConvBlock: 3-55                           [2, 640, 32, 32]          6,199,200\n",
       "│    │    └─MBConvBlock: 3-56                           [2, 640, 32, 32]          6,199,200\n",
       "├─UnetPlusPlusDecoder: 1-2                              [2, 16, 1024, 1024]       --\n",
       "│    └─ModuleDict: 2-5                                  --                        --\n",
       "│    │    └─DecoderBlock: 3-57                          [2, 256, 64, 64]          2,581,504\n",
       "│    │    └─DecoderBlock: 3-58                          [2, 80, 128, 128]         276,800\n",
       "│    │    └─DecoderBlock: 3-59                          [2, 48, 256, 256]         76,224\n",
       "│    │    └─DecoderBlock: 3-60                          [2, 64, 512, 512]         101,632\n",
       "│    │    └─DecoderBlock: 3-61                          [2, 128, 128, 128]        627,200\n",
       "│    │    └─DecoderBlock: 3-62                          [2, 48, 256, 256]         96,960\n",
       "│    │    └─DecoderBlock: 3-63                          [2, 64, 512, 512]         138,496\n",
       "│    │    └─DecoderBlock: 3-64                          [2, 64, 256, 256]         193,792\n",
       "│    │    └─DecoderBlock: 3-65                          [2, 64, 512, 512]         175,360\n",
       "│    │    └─DecoderBlock: 3-66                          [2, 32, 512, 512]         101,504\n",
       "│    │    └─DecoderBlock: 3-67                          [2, 16, 1024, 1024]       6,976\n",
       "├─SegmentationHead: 1-3                                 [2, 4, 1024, 1024]        --\n",
       "│    └─Conv2d: 2-6                                      [2, 4, 1024, 1024]        580\n",
       "│    └─Identity: 2-7                                    [2, 4, 1024, 1024]        --\n",
       "│    └─Activation: 2-8                                  [2, 4, 1024, 1024]        --\n",
       "│    │    └─Identity: 3-68                              [2, 4, 1024, 1024]        --\n",
       "=========================================================================================================\n",
       "Total params: 68,163,988\n",
       "Trainable params: 68,163,988\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 385.05\n",
       "=========================================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 19194.18\n",
       "Params size (MB): 18.73\n",
       "Estimated Total Size (MB): 19238.08\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=len(class_list),                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "def dice_loss(pred, target, num_classes=len(class_list)):\n",
    "    smooth = 1e-6\n",
    "    dice_per_class = torch.zeros((len(pred),num_classes)).to(pred.device)\n",
    "    pred=F.softmax(pred,dim=1)\n",
    "    for i in range(len(pred)):\n",
    "        for class_id in range(num_classes):\n",
    "            pred_class = pred[i, class_id, ...]\n",
    "            target_class = target[i, class_id, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * target_class)\n",
    "            A_sum = torch.sum(pred_class * pred_class)\n",
    "            B_sum = torch.sum(target_class * target_class)\n",
    "            dice_per_class[i,class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return 1-dice_per_class.mean()\n",
    "summary(model,(batch_size,3,img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/354 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/1000 Step: 355 dice_loss : 0.6552 dice_score: 0.3448: 100%|██████████| 354/354 [02:38<00:00,  2.23it/s]\n",
      "test epoch: 1/1000 Step: 89 dice_loss : 0.5781  dice_score: 0.4219: 100%|██████████| 88/88 [00:11<00:00,  7.78it/s]\n",
      "epoch: 2/1000 Step: 101 dice_loss : 0.5707 dice_score: 0.4293:  28%|██▊       | 100/354 [00:44<01:53,  2.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# optimizer zero 로 초기화\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m cost \u001b[38;5;241m=\u001b[39m dice_loss(predict, y) \u001b[38;5;66;03m# cost 구함\u001b[39;00m\n\u001b[1;32m     22\u001b[0m acc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mcost\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:38\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m---> 38\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m     41\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/efficientnet.py:72\u001b[0m, in \u001b[0;36mEfficientNetEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m             drop_connect \u001b[38;5;241m=\u001b[39m drop_connect_rate \u001b[38;5;241m*\u001b[39m block_number \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocks)\n\u001b[1;32m     71\u001b[0m             block_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 72\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_connect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/efficientnet_pytorch/model.py:130\u001b[0m, in \u001b[0;36mMBConvBlock.forward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_skip \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_block_args\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m input_filters \u001b[38;5;241m==\u001b[39m output_filters:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# The combination of skip connection and drop connect brings about stochastic depth.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_connect_rate:\n\u001b[0;32m--> 130\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mdrop_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_connect_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m inputs  \u001b[38;5;66;03m# skip connection\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/efficientnet_pytorch/utils.py:129\u001b[0m, in \u001b[0;36mdrop_connect\u001b[0;34m(inputs, p, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# follow the formula transferred from official TensorFlow implementation\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mceil(multiplier \u001b[38;5;241m*\u001b[39m repeats))\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop_connect\u001b[39m(inputs, p, training):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Drop connect.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        output: Output after drop connection.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp must be in range of [0,1]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "\n",
    "MIN_loss=5000\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
    "metrics = defaultdict(float)\n",
    "for epoch in range(1000):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = dice_loss(predict, y) # cost 구함\n",
    "        acc=1-cost.item()\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        y = y.to('cpu')\n",
    "\n",
    "        x=x.to('cpu')\n",
    "        train.set_description(f\"epoch: {epoch+1}/{1000} Step: {count+1} dice_loss : {running_loss/count:.4f} dice_score: {1-running_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count))\n",
    "#test\n",
    "    val=tqdm(test_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            cost = dice_loss(predict, y) # cost 구함\n",
    "            acc=1-cost.item()\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            y = y.to('cpu')\n",
    "            x=x.to('cpu')\n",
    "            val.set_description(f\"test epoch: {epoch+1}/{1000} Step: {count+1} dice_loss : {val_running_loss/count:.4f}  dice_score: {1-val_running_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count))\n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        createDirectory('../../model/synth_autolabel/_STIN/')\n",
    "        torch.save(model.state_dict(), '../../model/synth_autolabel/_STIN/check.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "    torch.save(model.state_dict(), '../../model/synth_autolabel/_STIN/'+str(epoch)+'.pt')\n",
    "    pred_mask1=torch.argmax(predict[0],0).cpu()\n",
    "    pred_mask=torch.zeros((3,img_size,img_size))\n",
    "    pred_mask[0]+=torch.where(pred_mask1==0,1,0)\n",
    "    pred_mask[1]+=torch.where(pred_mask1==1,1,0)\n",
    "    pred_mask[2]+=torch.where(pred_mask1==2,1,0)\n",
    "    pred_mask[0]+=torch.where(pred_mask1==3,1,0)\n",
    "    pred_mask[1]+=torch.where(pred_mask1==3,1,0)\n",
    "    label_mask1=torch.argmax(y[0],0).cpu()\n",
    "    label_mask=torch.zeros((3,img_size,img_size))\n",
    "    label_mask[0]+=torch.where(label_mask1==0,1,0)\n",
    "    label_mask[1]+=torch.where(label_mask1==1,1,0)\n",
    "    label_mask[2]+=torch.where(label_mask1==2,1,0)\n",
    "    label_mask[0]+=torch.where(label_mask1==3,1,0)\n",
    "    label_mask[1]+=torch.where(label_mask1==3,1,0)\n",
    "    label_overlay=x[0].cpu()*0.7+label_mask*0.3\n",
    "    pred_overlay=x[0].cpu()*0.7+pred_mask*0.3\n",
    "    createDirectory('../../result/synth_autolabel/_STIN/')\n",
    "    topilimage(torch.concat((label_overlay,pred_overlay),2)).save('../../result/synth_autolabel/_STIN/'+str(epoch)+'.jpeg')    \n",
    "    if epoch%50==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='test_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='test_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "torch.save(model.state_dict(), '../../model/synth_autolabel/_STIN/final.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
