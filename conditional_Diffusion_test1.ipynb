{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import get_rank, init_process_group, destroy_process_group, all_gather, get_world_size\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from conditionDiffusion.unet import Unet\n",
    "from conditionDiffusion.embedding import ConditionalEmbedding\n",
    "from conditionDiffusion.utils import get_named_beta_schedule\n",
    "from conditionDiffusion.diffusion import GaussianDiffusion\n",
    "from conditionDiffusion.Scheduler import GradualWarmupScheduler\n",
    "from PIL import Image\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",4)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "import pytorch_model_summary as tms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['유형1','유형2']\n",
    "params={'image_size':1024,\n",
    "        'lr':1e-5,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'image_count':5000,\n",
    "        'inch':3,\n",
    "        'modch':32,\n",
    "        'outch':3,\n",
    "        'chmul':[1,2,4,8,16,32,32],\n",
    "        'numres':2,\n",
    "        'dtype':torch.float32,\n",
    "        'cdim':10,\n",
    "        'useconv':False,\n",
    "        'droprate':0.1,\n",
    "        'T':1000,\n",
    "        'w':1.8,\n",
    "        'v':0.3,\n",
    "        'multiplier':2.5,\n",
    "        'threshold':0.1,\n",
    "        'ddim':True,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(in_ch = params['inch'],\n",
    "            mod_ch = params['modch'],\n",
    "            out_ch = params['outch'],\n",
    "            ch_mul = params['chmul'],\n",
    "            num_res_blocks = params['numres'],\n",
    "            cdim = params['cdim'],\n",
    "            use_conv = params['useconv'],\n",
    "            droprate = params['droprate'],\n",
    "            dtype = params['dtype']\n",
    "            ).to(device)\n",
    "cemblayer = ConditionalEmbedding(len(class_list), params['cdim'], params['cdim']).to(device)\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps = params['T'])\n",
    "diffusion = GaussianDiffusion(\n",
    "                    dtype = params['dtype'],\n",
    "                    model = net,\n",
    "                    betas = betas,\n",
    "                    w = params['w'],\n",
    "                    v = params['v'],\n",
    "                    device = device\n",
    "                )\n",
    "optimizer = torch.optim.AdamW(\n",
    "                itertools.chain(\n",
    "                    diffusion.model.parameters(),\n",
    "                    cemblayer.parameters()\n",
    "                ),\n",
    "                lr = params['lr'],\n",
    "                weight_decay = 1e-4\n",
    "            )\n",
    "\n",
    "\n",
    "cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                            optimizer = optimizer,\n",
    "                            T_max = params['epochs']/100,\n",
    "                            eta_min = 0,\n",
    "                            last_epoch = -1\n",
    "                        )\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "                        optimizer = optimizer,\n",
    "                        multiplier = params['multiplier'],\n",
    "                        warm_epoch = params['epochs'] // 10,\n",
    "                        after_scheduler = cosineScheduler,\n",
    "                        last_epoch = 0\n",
    "                    )\n",
    "\n",
    "checkpoint=torch.load(f'../../model/conditionDiff/details/STNT/ckpt_281_checkpoint.pt',map_location=device)\n",
    "diffusion.model.load_state_dict(checkpoint['net'])\n",
    "cemblayer.load_state_dict(checkpoint['cemblayer'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "warmUpScheduler.load_state_dict(checkpoint['scheduler'])\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:00<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n",
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [03:16<03:28,  8.70s/it]"
     ]
    }
   ],
   "source": [
    "diffusion.model.eval()\n",
    "cemblayer.eval()\n",
    "all_samples = []\n",
    "class1_count=0\n",
    "class2_count=0\n",
    "each_device_batch =30\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "with torch.no_grad():\n",
    "    lab = torch.ones(len(class_list), each_device_batch // len(class_list)).type(torch.long) \\\n",
    "    * torch.arange(start = 0, end = len(class_list)).reshape(-1, 1)\n",
    "    lab = lab.reshape(-1, 1).squeeze()\n",
    "    lab = lab.to(device)\n",
    "    cemb = cemblayer(lab)\n",
    "    genshape = (each_device_batch , 3, params['image_size'], params['image_size'])\n",
    "    for k in range(20):\n",
    "        generated = diffusion.ddim_sample(genshape, 50, 0, 'linear', cemb = cemb)\n",
    "        generated=transback(generated)\n",
    "        for i in range(len(lab)):\n",
    "            img_pil = topilimage(generated[i].cpu())\n",
    "            if lab[i]==0:\n",
    "                img_pil.save(f'../../result/Detail/STNT/Generator_image/유형1/{class1_count}.png')\n",
    "                class1_count+=1\n",
    "            else:\n",
    "                img_pil.save(f'../../result/Detail/STNT/Generator_image/유형2/{class2_count}.png')\n",
    "                class2_count+=1\n",
    "    #generated = diffusion.sample(genshape, cemb = cemb)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
