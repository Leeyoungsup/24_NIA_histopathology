{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:6\n"
     ]
    }
   ],
   "source": [
    "import pytorch_model_summary as tms\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import get_rank, init_process_group, destroy_process_group, all_gather, get_world_size\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from conditionDiffusion.unet import Unet\n",
    "from conditionDiffusion.embedding import ConditionalEmbedding\n",
    "from conditionDiffusion.utils import get_named_beta_schedule\n",
    "from conditionDiffusion.Scheduler import GradualWarmupScheduler\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributed import get_rank\n",
    "import imageio\n",
    "\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\", 6)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['유형11', '유형12','유형13','유형14']\n",
    "model_path='../../model/conditionDiff/color_scratch_details/STMX/ckpt_101_checkpoint.pt'\n",
    "params = {'image_size': 1024,\n",
    "          'lr': 2e-5,\n",
    "          'beta1': 0.5,\n",
    "          'beta2': 0.999,\n",
    "          'batch_size': 1,\n",
    "          'epochs': 1000,\n",
    "          'n_classes': None,\n",
    "          'data_path': '../../result/synth_gif/STMX/',\n",
    "          'image_count': 5000,\n",
    "          'inch': 3,\n",
    "          'modch': 128,\n",
    "          'outch': 3,\n",
    "          'chmul': [1, 2, 4, 4, 4],\n",
    "          'numres': 2,\n",
    "          'dtype': torch.float32,\n",
    "          'cdim': 256,\n",
    "          'useconv': False,\n",
    "          'droprate': 0.1,\n",
    "          'T': 1000,\n",
    "          'w': 1.8,\n",
    "          'v': 0.3,\n",
    "          'multiplier': 1,\n",
    "          'threshold': 0.02,\n",
    "          'ddim': True,\n",
    "          }\n",
    "tf = transforms.ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "\n",
    "def transback(data: Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "\n",
    "    def __init__(self, parmas, images, label):\n",
    "\n",
    "        self.images = images\n",
    "        self.args = parmas\n",
    "        self.label = label\n",
    "\n",
    "    def trans(self, image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.label[index]\n",
    "        image = self.trans(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, 64, 7),\n",
    "                 nn.InstanceNorm2d(64),\n",
    "                 nn.ReLU(inplace=True)]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(64, output_nc, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, dtype: torch.dtype, model, betas: np.ndarray, w: float, v: float, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.model = model.to(device)\n",
    "        self.model.dtype = self.dtype\n",
    "        self.betas = torch.tensor(betas, dtype=self.dtype)\n",
    "        self.w = w\n",
    "        self.v = v\n",
    "        self.T = len(betas)\n",
    "        self.device = device\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.log_alphas = torch.log(self.alphas)\n",
    "\n",
    "        self.log_alphas_bar = torch.cumsum(self.log_alphas, dim=0)\n",
    "        self.alphas_bar = torch.exp(self.log_alphas_bar)\n",
    "        # self.alphas_bar = torch.cumprod(self.alphas, dim = 0)\n",
    "\n",
    "        self.log_alphas_bar_prev = F.pad(\n",
    "            self.log_alphas_bar[:-1], [1, 0], 'constant', 0)\n",
    "        self.alphas_bar_prev = torch.exp(self.log_alphas_bar_prev)\n",
    "        self.log_one_minus_alphas_bar_prev = torch.log(\n",
    "            1.0 - self.alphas_bar_prev)\n",
    "        # self.alphas_bar_prev = F.pad(self.alphas_bar[:-1],[1,0],'constant',1)\n",
    "\n",
    "        # calculate parameters for q(x_t|x_{t-1})\n",
    "        self.log_sqrt_alphas = 0.5 * self.log_alphas\n",
    "        self.sqrt_alphas = torch.exp(self.log_sqrt_alphas)\n",
    "        # self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "\n",
    "        # calculate parameters for q(x_t|x_0)\n",
    "        self.log_sqrt_alphas_bar = 0.5 * self.log_alphas_bar\n",
    "        self.sqrt_alphas_bar = torch.exp(self.log_sqrt_alphas_bar)\n",
    "        # self.sqrt_alphas_bar = torch.sqrt(self.alphas_bar)\n",
    "        self.log_one_minus_alphas_bar = torch.log(1.0 - self.alphas_bar)\n",
    "        self.sqrt_one_minus_alphas_bar = torch.exp(\n",
    "            0.5 * self.log_one_minus_alphas_bar)\n",
    "\n",
    "        # calculate parameters for q(x_{t-1}|x_t,x_0)\n",
    "        # log calculation clipped because the \\tilde{\\beta} = 0 at the beginning\n",
    "        self.tilde_betas = self.betas * \\\n",
    "            torch.exp(self.log_one_minus_alphas_bar_prev -\n",
    "                      self.log_one_minus_alphas_bar)\n",
    "        self.log_tilde_betas_clipped = torch.log(\n",
    "            torch.cat((self.tilde_betas[1].view(-1), self.tilde_betas[1:]), 0))\n",
    "        self.mu_coef_x0 = self.betas * \\\n",
    "            torch.exp(0.5 * self.log_alphas_bar_prev -\n",
    "                      self.log_one_minus_alphas_bar)\n",
    "        self.mu_coef_xt = torch.exp(\n",
    "            0.5 * self.log_alphas + self.log_one_minus_alphas_bar_prev - self.log_one_minus_alphas_bar)\n",
    "        self.vars = torch.cat((self.tilde_betas[1:2], self.betas[1:]), 0)\n",
    "        self.coef1 = torch.exp(-self.log_sqrt_alphas)\n",
    "        self.coef2 = self.coef1 * self.betas / self.sqrt_one_minus_alphas_bar\n",
    "        # calculate parameters for predicted x_0\n",
    "        self.sqrt_recip_alphas_bar = torch.exp(-self.log_sqrt_alphas_bar)\n",
    "        # self.sqrt_recip_alphas_bar = torch.sqrt(1.0 / self.alphas_bar)\n",
    "        self.sqrt_recipm1_alphas_bar = torch.exp(\n",
    "            self.log_one_minus_alphas_bar - self.log_sqrt_alphas_bar)\n",
    "        # self.sqrt_recipm1_alphas_bar = torch.sqrt(1.0 / self.alphas_bar - 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract(coef: torch.Tensor, t: torch.Tensor, x_shape: tuple) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        input:\n",
    "\n",
    "        coef : an array\n",
    "        t : timestep\n",
    "        x_shape : the shape of tensor x that has K dims(the value of first dim is batch size)\n",
    "\n",
    "        output:\n",
    "\n",
    "        a tensor of shape [batchsize,1,...] where the length has K dims.\n",
    "        \"\"\"\n",
    "        assert t.shape[0] == x_shape[0]\n",
    "\n",
    "        neo_shape = torch.ones_like(torch.tensor(x_shape))\n",
    "        neo_shape[0] = x_shape[0]\n",
    "        neo_shape = neo_shape.tolist()\n",
    "        coef = coef.to(t.device)\n",
    "        chosen = coef[t]\n",
    "        chosen = chosen.to(t.device)\n",
    "        return chosen.reshape(neo_shape)\n",
    "\n",
    "    def q_mean_variance(self, x_0: torch.Tensor, t: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        calculate the parameters of q(x_t|x_0)\n",
    "        \"\"\"\n",
    "        mean = self._extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0\n",
    "        var = self._extract(1.0 - self.sqrt_alphas_bar, t, x_0.shape)\n",
    "        return mean, var\n",
    "\n",
    "    def q_sample(self, x_0: torch.Tensor, t: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        sample from q(x_t|x_0)\n",
    "        \"\"\"\n",
    "        eps = torch.randn_like(x_0, requires_grad=False)\n",
    "        return self._extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 \\\n",
    "            + self._extract(self.sqrt_one_minus_alphas_bar,\n",
    "                            t, x_0.shape) * eps, eps\n",
    "\n",
    "    def q_posterior_mean_variance(self, x_0: torch.Tensor, x_t: torch.Tensor, t: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        calculate the parameters of q(x_{t-1}|x_t,x_0)\n",
    "        \"\"\"\n",
    "        posterior_mean = self._extract(self.mu_coef_x0, t, x_0.shape) * x_0 \\\n",
    "            + self._extract(self.mu_coef_xt, t, x_t.shape) * x_t\n",
    "        posterior_var_max = self._extract(self.tilde_betas, t, x_t.shape)\n",
    "        log_posterior_var_min = self._extract(\n",
    "            self.log_tilde_betas_clipped, t, x_t.shape)\n",
    "        log_posterior_var_max = self._extract(\n",
    "            torch.log(self.betas), t, x_t.shape)\n",
    "        log_posterior_var = self.v * log_posterior_var_max + \\\n",
    "            (1 - self.v) * log_posterior_var_min\n",
    "        neo_posterior_var = torch.exp(log_posterior_var)\n",
    "\n",
    "        return posterior_mean, posterior_var_max, neo_posterior_var\n",
    "\n",
    "    def p_mean_variance(self, x_t: torch.Tensor, t: torch.Tensor, **model_kwargs) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        calculate the parameters of p_{theta}(x_{t-1}|x_t)\n",
    "        \"\"\"\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        B, C = x_t.shape[:2]\n",
    "        assert t.shape == (B,)\n",
    "        cemb_shape = model_kwargs['cemb'].shape\n",
    "        pred_eps_cond = self.model(x_t, t, **model_kwargs)\n",
    "        model_kwargs['cemb'] = torch.zeros(cemb_shape, device=self.device)\n",
    "        pred_eps_uncond = self.model(x_t, t, **model_kwargs)\n",
    "        pred_eps = (1 + self.w) * pred_eps_cond - self.w * pred_eps_uncond\n",
    "\n",
    "        assert torch.isnan(x_t).int().sum(\n",
    "        ) == 0, f\"nan in tensor x_t when t = {t[0]}\"\n",
    "        assert torch.isnan(t).int().sum(\n",
    "        ) == 0, f\"nan in tensor t when t = {t[0]}\"\n",
    "        assert torch.isnan(pred_eps).int().sum(\n",
    "        ) == 0, f\"nan in tensor pred_eps when t = {t[0]}\"\n",
    "        p_mean = self._predict_xt_prev_mean_from_eps(\n",
    "            x_t, t.type(dtype=torch.long), pred_eps)\n",
    "        p_var = self._extract(self.vars, t.type(dtype=torch.long), x_t.shape)\n",
    "        return p_mean, p_var\n",
    "\n",
    "    def _predict_x0_from_eps(self, x_t: torch.Tensor, t: torch.Tensor, eps: torch.Tensor) -> torch.Tensor:\n",
    "        return self._extract(coef=self.sqrt_recip_alphas_bar, t=t, x_shape=x_t.shape) \\\n",
    "            * x_t - self._extract(coef=self.sqrt_one_minus_alphas_bar, t=t, x_shape=x_t.shape) * eps\n",
    "\n",
    "    def _predict_xt_prev_mean_from_eps(self, x_t: torch.Tensor, t: torch.Tensor, eps: torch.Tensor) -> torch.Tensor:\n",
    "        return self._extract(coef=self.coef1, t=t, x_shape=x_t.shape) * x_t - \\\n",
    "            self._extract(coef=self.coef2, t=t, x_shape=x_t.shape) * eps\n",
    "\n",
    "    def p_sample(self, x_t: torch.Tensor, t: torch.Tensor, **model_kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        sample x_{t-1} from p_{theta}(x_{t-1}|x_t)\n",
    "        \"\"\"\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        B, C = x_t.shape[:2]\n",
    "        assert t.shape == (B,), f\"size of t is not batch size {B}\"\n",
    "        mean, var = self.p_mean_variance(x_t, t, **model_kwargs)\n",
    "        assert torch.isnan(mean).int().sum(\n",
    "        ) == 0, f\"nan in tensor mean when t = {t[0]}\"\n",
    "        assert torch.isnan(var).int().sum(\n",
    "        ) == 0, f\"nan in tensor var when t = {t[0]}\"\n",
    "        noise = torch.randn_like(x_t)\n",
    "        noise[t <= 0] = 0\n",
    "        return mean + torch.sqrt(var) * noise\n",
    "\n",
    "    def sample(self, shape: tuple, **model_kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        sample images from p_{theta}\n",
    "        \"\"\"\n",
    "        local_rank = 0\n",
    "        if local_rank == 0:\n",
    "            print('Start generating...')\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        x_t = torch.randn(shape, device=self.device)\n",
    "\n",
    "        tlist = torch.ones([x_t.shape[0]], device=self.device) * self.T\n",
    "        for _ in tqdm(range(self.T), dynamic_ncols=True, disable=(local_rank % torch.cuda.device_count() != 0)):\n",
    "            tlist -= 1\n",
    "            with torch.no_grad():\n",
    "                x_t = self.p_sample(x_t, tlist, **model_kwargs)\n",
    "        x_t = torch.clamp(x_t, -1, 1)\n",
    "        if local_rank == 0:\n",
    "            print('ending sampling process...')\n",
    "        return x_t\n",
    "\n",
    "    def ddim_p_mean_variance(self, x_t: torch.Tensor, t: torch.Tensor, prevt: torch.Tensor, eta: float, **model_kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate the parameters of p_{theta}(x_{t-1}|x_t)\n",
    "        \"\"\"\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        B, C = x_t.shape[:2]\n",
    "        assert t.shape == (B,)\n",
    "        cemb_shape = model_kwargs['cemb'].shape\n",
    "        pred_eps_cond = self.model(x_t, t, **model_kwargs)\n",
    "        model_kwargs['cemb'] = torch.zeros(cemb_shape, device=self.device)\n",
    "        pred_eps_uncond = self.model(x_t, t, **model_kwargs)\n",
    "        pred_eps = (1 + self.w) * pred_eps_cond - self.w * pred_eps_uncond\n",
    "\n",
    "        assert torch.isnan(x_t).int().sum(\n",
    "        ) == 0, f\"nan in tensor x_t when t = {t[0]}\"\n",
    "        assert torch.isnan(t).int().sum(\n",
    "        ) == 0, f\"nan in tensor t when t = {t[0]}\"\n",
    "        assert torch.isnan(pred_eps).int().sum(\n",
    "        ) == 0, f\"nan in tensor pred_eps when t = {t[0]}\"\n",
    "\n",
    "        alphas_bar_t = self._extract(\n",
    "            coef=self.alphas_bar, t=t, x_shape=x_t.shape)\n",
    "        alphas_bar_prev = self._extract(\n",
    "            coef=self.alphas_bar_prev, t=prevt + 1, x_shape=x_t.shape)\n",
    "        sigma = eta * torch.sqrt((1 - alphas_bar_prev) / (1 -\n",
    "                                 alphas_bar_t) * (1 - alphas_bar_t / alphas_bar_prev))\n",
    "        p_var = sigma ** 2\n",
    "        coef_eps = 1 - alphas_bar_prev - p_var\n",
    "        coef_eps[coef_eps < 0] = 0\n",
    "        coef_eps = torch.sqrt(coef_eps)\n",
    "        p_mean = torch.sqrt(alphas_bar_prev) * (x_t - torch.sqrt(1 - alphas_bar_t) * pred_eps) / torch.sqrt(alphas_bar_t) + \\\n",
    "            coef_eps * pred_eps\n",
    "        return p_mean, p_var\n",
    "\n",
    "    def ddim_p_sample(self, x_t: torch.Tensor, t: torch.Tensor, prevt: torch.Tensor, eta: float, **model_kwargs) -> torch.Tensor:\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        B, C = x_t.shape[:2]\n",
    "        assert t.shape == (B,), f\"size of t is not batch size {B}\"\n",
    "        mean, var = self.ddim_p_mean_variance(x_t, t.type(\n",
    "            dtype=torch.long), prevt.type(dtype=torch.long), eta, **model_kwargs)\n",
    "        assert torch.isnan(mean).int().sum(\n",
    "        ) == 0, f\"nan in tensor mean when t = {t[0]}\"\n",
    "        assert torch.isnan(var).int().sum(\n",
    "        ) == 0, f\"nan in tensor var when t = {t[0]}\"\n",
    "        noise = torch.randn_like(x_t)\n",
    "        noise[t <= 0] = 0\n",
    "        return mean + torch.sqrt(var) * noise\n",
    "\n",
    "    def ddim_sample(self, shape: tuple, num_steps: int, eta: float, select: str, **model_kwargs) -> torch.Tensor:\n",
    "        local_rank = 0\n",
    "        if local_rank == 0:\n",
    "            print('Start generating(ddim)...')\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        # a subsequence of range(0,1000)\n",
    "        if select == 'linear':\n",
    "            tseq = list(np.linspace(0, self.T-1, num_steps).astype(int))\n",
    "        elif select == 'quadratic':\n",
    "            tseq = list(\n",
    "                (np.linspace(0, np.sqrt(self.T), num_steps-1)**2).astype(int))\n",
    "            tseq.insert(0, 0)\n",
    "            tseq[-1] = self.T - 1\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f'There is no ddim discretization method called \"{select}\"')\n",
    "\n",
    "        x_t = torch.randn(shape, device=self.device)\n",
    "        x_t1=x_t.unsqueeze(0)\n",
    "        tlist = torch.zeros([x_t.shape[0]], device=self.device)\n",
    "        for i in tqdm(range(num_steps), dynamic_ncols=True, disable=(local_rank % torch.cuda.device_count() != 0)):\n",
    "            with torch.no_grad():\n",
    "                tlist = tlist * 0 + tseq[-1-i]\n",
    "                if i != num_steps - 1:\n",
    "                    prevt = torch.ones_like(\n",
    "                        tlist, device=self.device) * tseq[-2-i]\n",
    "                else:\n",
    "                    prevt = - torch.ones_like(tlist, device=self.device)\n",
    "                x_t = self.ddim_p_sample(\n",
    "                    x_t, tlist, prevt, eta, **model_kwargs)\n",
    "                x_t1=torch.concat((x_t1,x_t.unsqueeze(0)),dim=0)\n",
    "                torch.cuda.empty_cache()\n",
    "        x_t = torch.clamp(x_t, -1, 1)\n",
    "        if local_rank == 0:\n",
    "            print('ending sampling process(ddim)...')\n",
    "        return x_t,x_t1\n",
    "\n",
    "    def trainloss(self, x_0: torch.Tensor, **model_kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate the loss of denoising diffusion probabilistic model\n",
    "        \"\"\"\n",
    "        if model_kwargs == None:\n",
    "            model_kwargs = {}\n",
    "        t = torch.randint(self.T, size=(x_0.shape[0],), device=self.device)\n",
    "        x_t, eps = self.q_sample(x_0, t)\n",
    "        pred_eps = self.model(x_t, t, **model_kwargs)\n",
    "        loss = F.mse_loss(pred_eps, eps, reduction='mean')\n",
    "        return loss\n",
    "\n",
    "    def trainloss_mask(self, x_0: torch.Tensor, **model_kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate the loss of denoising diffusion probabilistic model\n",
    "        \"\"\"\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = {}\n",
    "        t = torch.randint(self.T, size=(x_0.shape[0],), device=self.device)\n",
    "        x_t, eps = self.q_sample(x_0, t)\n",
    "        pred_eps = self.model(x_t, t, **model_kwargs)\n",
    "        loss = F.mse_loss(pred_eps, eps, reduction='mean')\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = Generator(3, 3).to(device)\n",
    "generator.load_state_dict(torch.load(\n",
    "    '../../model/cyclegan/G_B_29.pth', map_location=device))\n",
    "\n",
    "\n",
    "net = Unet(in_ch=params['inch'],\n",
    "           mod_ch=params['modch'],\n",
    "           out_ch=params['outch'],\n",
    "           ch_mul=params['chmul'],\n",
    "           num_res_blocks=params['numres'],\n",
    "           cdim=params['cdim'],\n",
    "           use_conv=params['useconv'],\n",
    "           droprate=params['droprate'],\n",
    "           dtype=params['dtype']\n",
    "           ).to(device)\n",
    "\n",
    "cemblayer = ConditionalEmbedding(\n",
    "    len(class_list), params['cdim'], params['cdim']).to(device)\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps=params['T'])\n",
    "diffusion = GaussianDiffusion(\n",
    "    dtype=params['dtype'],\n",
    "    model=net,\n",
    "    betas=betas,\n",
    "    w=params['w'],\n",
    "    v=params['v'],\n",
    "    device=device\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    itertools.chain(\n",
    "        diffusion.model.parameters(),\n",
    "        cemblayer.parameters()\n",
    "    ),\n",
    "    lr=params['lr'],\n",
    "    weight_decay=1e-6\n",
    ")\n",
    "\n",
    "\n",
    "cosineScheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "    optimizer=optimizer,\n",
    "    multiplier=params['multiplier'],\n",
    "    warm_epoch=100,\n",
    "    after_scheduler=cosineScheduler,\n",
    "    last_epoch=0\n",
    ")\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "diffusion.model.load_state_dict(checkpoint['net'])\n",
    "cemblayer.load_state_dict(checkpoint['cemblayer'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "warmUpScheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating(ddim)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:21<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending sampling process(ddim)...\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 0\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "diffusion.model.eval()\n",
    "cemblayer.eval()\n",
    "all_samples = []\n",
    "each_device_batch = len(class_list)\n",
    "with torch.no_grad():\n",
    "    lab = torch.ones(len(class_list), each_device_batch // len(class_list)).type(torch.long)*torch.arange(start=0, end=len(class_list)).reshape(-1, 1)\n",
    "    # lab = torch.tensor([[0, 0, 1, 4], [0, 0,1, 4]], dtype=torch.long)\n",
    "    lab = lab.reshape(-1, 1).squeeze()\n",
    "    lab = lab.to(device)\n",
    "    cemb = cemblayer(lab)\n",
    "    genshape = (len(lab), params['outch'],\n",
    "                params['image_size'], params['image_size'])\n",
    "    if params['ddim']:\n",
    "        generated,x_t = diffusion.ddim_sample(\n",
    "            genshape, 100, 0.0, 'quadratic', cemb=cemb)\n",
    "    else:\n",
    "        generated = diffusion.sample(genshape, cemb=cemb)\n",
    "    generated = generated.to(device)\n",
    "    for i in range(len(lab)):\n",
    "        images = [topilimage(transback(image_file)).resize((512,512)) for image_file in x_t[:,i,...]]\n",
    "        createDirectory(params['data_path']+f'{class_list[lab[i]]}')\n",
    "        images[0].save(params['data_path']+f'{class_list[lab[i]]}/NIA_S_ST_{class_list[lab[i]][2:]}.gif',\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=50,  # 각 이미지의 지속 시간 (500ms)\n",
    "            loop=0)   \n",
    "        img_pil = topilimage(transback(generated[i].cpu()))\n",
    "        img_pil.save(\n",
    "                params['data_path']+f'{class_list[lab[i]]}/NIA_S_ST_{class_list[lab[i]][2:]}_ori.jpeg')\n",
    "        img_pil = topilimage(transback(generator(generated[i])).cpu())\n",
    "        img_pil.save(\n",
    "                params['data_path']+f'{class_list[lab[i]]}/NIA_S_ST_{class_list[lab[i]][2:]}_cy.jpeg')\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
