{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import albumentations as A\n",
    "from pathSeg.ml.hovernet import HoVerNet, loss_hovernet, post_process_batch_hovernet\n",
    "from pathSeg.ml.utils import dice_score\n",
    "from pathSeg.utils import plot_segmentation\n",
    "import pytorch_model_summary as tms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.io\n",
    "from glob import glob\n",
    "from PIL import Image   \n",
    "from loguru import logger\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import torchvision\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda:5\")\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12649"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('../../result/nucleus_segmentation/**/**/*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['유형1','유형2']\n",
    "params={'image_size':1024,\n",
    "        'lr':1e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'data_path':'../../data/origin_json/**/**/',}\n",
    "\n",
    "tf = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_mask_to_polygon(binary_mask):\n",
    "    # binary_mask는 2차원 numpy array여야 합니다.\n",
    "    # Contours를 찾습니다.\n",
    "    contours=[]\n",
    "    k11=cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    for i in range(1,binary_mask.max()):\n",
    "        mask=np.where(binary_mask==i,1,0).astype(np.uint8)\n",
    "        mask=cv2.morphologyEx(mask, cv2.MORPH_OPEN,k11 )\n",
    "        try:\n",
    "            contour, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        except:\n",
    "            contour=()\n",
    "        if(len(contour)!=0):\n",
    "            contours.append(contour[0])\n",
    "    polygons = []\n",
    "    contours = [cnt for cnt in contours if cv2.contourArea(cnt) >= 10]\n",
    "    for contour in contours:\n",
    "        # 각 contour를 polygon으로 변환\n",
    "        if len(contour) >= 3:  # 유효한 polygon을 만들기 위해서 최소한 3개의 점이 필요합니다.\n",
    "            poly = Polygon(shell=[(point[0][0], point[0][1]) for point in contour])\n",
    "            polygons.append(poly)\n",
    "    \n",
    "    if len(polygons) > 1:\n",
    "        # 여러 개의 polygon이 있을 경우 MultiPolygon으로 변환\n",
    "        return MultiPolygon(polygons)\n",
    "    elif len(polygons) == 1:\n",
    "        return MultiPolygon(polygons)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def mask2polygon(mask):\n",
    "    poly=binary_mask_to_polygon(mask)\n",
    "\n",
    "    polygon_arrays = []\n",
    "\n",
    "    if poly!=None:\n",
    "        for polygon in poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            polygon_arrays.append(exterior_coords)\n",
    "  \n",
    "    return  polygon_arrays\n",
    "\n",
    "def polygon2asap(label_polygon,class_list,save_path):\n",
    "    # 루트 엘리먼트 생성\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    # Annotations 엘리먼트 생성 및 루트에 추가\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    for i in range(len(label_polygon)):\n",
    "        \n",
    "        for j in range(len(label_polygon[i])):\n",
    "            annotation = ET.SubElement(annotations, \"Annotation\", Name=class_list[i], Type=\"Polygon\", PartOfGroup=\"None\", Color=\"#F4FA58\")\n",
    "            coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "            for k in range(len(label_polygon[i][j])):\n",
    "                ET.SubElement(coordinates, \"Coordinate\", Order=str(k), X=str(float(label_polygon[i][j][k,0])), Y=str(float(label_polygon[i][j][k,1])))\n",
    "            \n",
    "            \n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(save_path)\n",
    "    \n",
    "def polygon2mask(image_shape, polygons):\n",
    "    # 빈 마스크 생성 (모든 채널을 0으로 초기화)\n",
    "    mask=np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    for polygon in polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(mask, [polygon], 255)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml_path='../../result/nucleus_segmentation/'\n",
    "image_list=[]\n",
    "category_list=[]\n",
    "for k in range(1):\n",
    "    img_list=glob('../../result/nucleus_segmentation/**/**/*.xml')\n",
    "    img_list1=[i.replace('.xml','.jpeg') for i in img_list]\n",
    "    img_list1=[i.replace('/result/nucleus_segmentation','/data/origin_json') for i in img_list1]\n",
    "    img_list=glob('../../data/origin_json/**/**/*.jpeg')\n",
    "    for i in range(len(img_list1)):\n",
    "        img_list.remove(img_list1[i])\n",
    "    image_list=img_list\n",
    "    category_list=img_list\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        self.tf= ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path=self.img_path[idx]\n",
    "        image=self.tf(Image.open(self.img_path[idx]))\n",
    "        label=self.label[idx]\n",
    "        return image,label,path\n",
    "\n",
    "dataset = CustomDataset(image_list, category_list)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "hovernet = HoVerNet(n_classes=params['n_classes']).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(hovernet.parameters(), lr = params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "# learning rate scheduler to reduce LR by factor of 10 each 25 epochs\n",
    "scheduler = StepLR(opt, step_size=25, gamma=0.1)\n",
    "checkpoint = torch.load(\"../../model/pathSeg/hovernet_binary_qupath_best_perf.pt\", map_location=device)\n",
    "hovernet.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3321/3321 [2:49:24<00:00,  3.06s/it]  \n"
     ]
    }
   ],
   "source": [
    "hovernet.eval()\n",
    "\n",
    "ims = None\n",
    "mask_truth = None\n",
    "mask_pred = None\n",
    "tissue_types = []\n",
    "path_list=[]\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "        # send the data to the GPU\n",
    "        images = data[0].float().to(device)\n",
    "        path=data[2]\n",
    "        label=os.path.basename(os.path.dirname(path[0]))\n",
    "        ac=os.path.basename(os.path.dirname(os.path.dirname(path[0])))\n",
    "        # pass thru network to get predictions\n",
    "        outputs = hovernet(images)\n",
    "        preds_detection = post_process_batch_hovernet(outputs, n_classes=params['n_classes'])\n",
    "        polygon=mask2polygon(preds_detection[0])\n",
    "        label_polygon=[polygon]\n",
    "        save_path=xml_path+ac+'/'+label+'/'+os.path.basename(path[0]).split('.')[0]+'.xml'\n",
    "        createDirectory(xml_path+ac+'/'+label+'/')\n",
    "        polygon2asap(label_polygon,['Cell_nucleus'],save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'유형7'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(os.path.dirname(path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../data/origin_json/STDI/유형7/NIA6_R_STDI_STOP-GH-00028-S-TP-01_7_10.jpeg',)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hovernet.eval()\n",
    "\n",
    "ims = None\n",
    "mask_truth = None\n",
    "mask_pred = None\n",
    "tissue_types = []\n",
    "name_list=[]\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        # send the data to the GPU\n",
    "        images = data[0].float().to(device)\n",
    "        file_name=os.path.basename(data[2][0])\n",
    "        name_list.append(file_name)\n",
    "        # pass thru network to get predictions\n",
    "        outputs = hovernet(images)\n",
    "        preds_detection = post_process_batch_hovernet(outputs, n_classes=params['n_classes'])\n",
    "        \n",
    "        if i == 0:\n",
    "            ims = data[0].numpy()\n",
    "            mask_pred = preds_detection\n",
    "\n",
    "        else:\n",
    "            ims = np.concatenate([ims, data[0].numpy()], axis=0)\n",
    "            mask_pred = np.concatenate([mask_pred, preds_detection], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_mask=np.zeros((len(mask_pred),1024,1024,3))\n",
    "cell_mask=np.zeros((len(mask_pred),1024,1024,3))\n",
    "area_path='../../data/segmentation/BR/BRNT/mask/npy/'\n",
    "for i in tqdm(range(len(mask_pred))):\n",
    "    temp_mask=np.load(area_path+name_list[i].replace('.jpeg', '.npy'))\n",
    "    area_mask[i]+=temp_mask\n",
    "    label_unique=np.unique(mask_pred[i])\n",
    "    for j in label_unique:\n",
    "        if j!=0:\n",
    "            x,y=np.where(mask_pred[i]==j)[0].mean(),np.where(mask_pred[i]==j)[1].mean()\n",
    "            mask_index=area_mask[i,int(x),int(y)]\n",
    "            if mask_index.sum()==0:\n",
    "                cell_mask[i,...,1]+=np.where(mask_pred[i]==j,j,0)\n",
    "            else:\n",
    "                cell_mask[i,...,mask_index.argmax()]+=np.where(mask_pred[i]==j,j,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims1 = np.moveaxis(ims, 1, 3)\n",
    "n = 5\n",
    "mask_pred1=np.transpose(cell_mask,(0,3,1,2))\n",
    "ix = np.array([10, 13, 12,  18,  2])\n",
    "fig, ax = plt.subplots(nrows = n, ncols = 2, figsize = (22, 10*n))\n",
    "for i, index in enumerate(ix):\n",
    "    ax[i, 0].imshow(ims1[index, ...])\n",
    "    ax[i, 1].imshow(ims1[index, ...])\n",
    "    plot_segmentation(ax = ax[i, 1], masks = mask_pred1[index, ...])\n",
    "        \n",
    "for a in ax.ravel(): \n",
    "    a.get_xaxis().set_ticks([])\n",
    "    a.get_yaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mask\n",
    "np.transpose(cell_mask[0],(2,0,1))[np.newaxis,:,:,:].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
