{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/onnx/_internal/_beartype.py:36: UserWarning: unhashable type: 'list'\n",
      "  warnings.warn(f\"{e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import albumentations as A\n",
    "from pathSeg.ml.hovernet import HoVerNet, loss_hovernet, post_process_batch_hovernet\n",
    "from pathSeg.ml.utils import dice_score\n",
    "from pathSeg.utils import plot_segmentation\n",
    "import pytorch_model_summary as tms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.io\n",
    "from glob import glob\n",
    "from PIL import Image   \n",
    "from loguru import logger\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import torchvision\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda:6\")\n",
    "print(f\"Device:\\t\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['유형1','유형2']\n",
    "params={'image_size':1024,\n",
    "        'lr':1e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'data_path':'../../data/segmentation/BR/BRNT/',}\n",
    "\n",
    "tf = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_mask_to_polygon(binary_mask):\n",
    "    # binary_mask는 2차원 numpy array여야 합니다.\n",
    "    # Contours를 찾습니다.\n",
    "    contours=[]\n",
    "    k11=cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    for i in range(1,binary_mask.max()):\n",
    "        mask=np.where(binary_mask==i,1,0).astype(np.uint8)\n",
    "        mask=cv2.morphologyEx(mask, cv2.MORPH_OPEN,k11 )\n",
    "        try:\n",
    "            contour, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        except:\n",
    "            contour=()\n",
    "        if(len(contour)!=0):\n",
    "            contours.append(contour[0])\n",
    "    polygons = []\n",
    "    contours = [cnt for cnt in contours if cv2.contourArea(cnt) >= 10]\n",
    "    for contour in contours:\n",
    "        # 각 contour를 polygon으로 변환\n",
    "        if len(contour) >= 3:  # 유효한 polygon을 만들기 위해서 최소한 3개의 점이 필요합니다.\n",
    "            poly = Polygon(shell=[(point[0][0], point[0][1]) for point in contour])\n",
    "            polygons.append(poly)\n",
    "    \n",
    "    if len(polygons) > 1:\n",
    "        # 여러 개의 polygon이 있을 경우 MultiPolygon으로 변환\n",
    "        return MultiPolygon(polygons)\n",
    "    elif len(polygons) == 1:\n",
    "        return MultiPolygon(polygons)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def mask2polygon(mask):\n",
    "    poly=binary_mask_to_polygon(mask)\n",
    "\n",
    "    polygon_arrays = []\n",
    "\n",
    "    if poly!=None:\n",
    "        for polygon in poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            polygon_arrays.append(exterior_coords)\n",
    "  \n",
    "    return  polygon_arrays\n",
    "\n",
    "def polygon2asap(label_polygon,class_list,save_path):\n",
    "    # 루트 엘리먼트 생성\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    # Annotations 엘리먼트 생성 및 루트에 추가\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    for i in range(len(label_polygon)):\n",
    "        \n",
    "        for j in range(len(label_polygon[i])):\n",
    "            annotation = ET.SubElement(annotations, \"Annotation\", Name=class_list[i], Type=\"Polygon\", PartOfGroup=\"None\", Color=\"#F4FA58\")\n",
    "            coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "            for k in range(len(label_polygon[i][j])):\n",
    "                ET.SubElement(coordinates, \"Coordinate\", Order=str(k), X=str(float(label_polygon[i][j][k,0])), Y=str(float(label_polygon[i][j][k,1])))\n",
    "            \n",
    "            \n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(save_path)\n",
    "    \n",
    "def polygon2mask(image_shape, polygons):\n",
    "    # 빈 마스크 생성 (모든 채널을 0으로 초기화)\n",
    "    mask=np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    for polygon in polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(mask, [polygon], 255)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml_path='../../result/nucleus_segmentation/BR/BRNT/'\n",
    "image_list=[]\n",
    "category_list=[]\n",
    "for k in range(len(class_list)):\n",
    "    img_list=glob(params['data_path']+class_list[k]+'/*.jpeg')\n",
    "    for i in range(len(img_list)):\n",
    "        image_list.append(img_list[i])\n",
    "        category_list.append(class_list[k])\n",
    "\n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        self.tf= ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path=self.img_path[idx]\n",
    "        image=self.tf(Image.open(self.img_path[idx]))\n",
    "        label=self.label[idx]\n",
    "        return image,label,path\n",
    "\n",
    "dataset = CustomDataset(image_list, category_list)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3042970/3542994141.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"../../model/pathSeg/hovernet_binary_qupath_best_perf.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "hovernet = HoVerNet(n_classes=params['n_classes']).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(hovernet.parameters(), lr = params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "# learning rate scheduler to reduce LR by factor of 10 each 25 epochs\n",
    "scheduler = StepLR(opt, step_size=25, gamma=0.1)\n",
    "checkpoint = torch.load(\"../../model/pathSeg/hovernet_binary_qupath_best_perf.pt\", map_location=device)\n",
    "hovernet.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3450 [00:15<14:33:01, 15.19s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/xml/etree/ElementTree.py:762\u001b[0m, in \u001b[0;36m_get_writer\u001b[0;34m(file_or_filename, encoding)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     write \u001b[38;5;241m=\u001b[39m \u001b[43mfile_or_filename\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# file_or_filename is a file name\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'write'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m label_polygon\u001b[38;5;241m=\u001b[39m[polygon]\n\u001b[1;32m     19\u001b[0m save_path\u001b[38;5;241m=\u001b[39mxml_path\u001b[38;5;241m+\u001b[39mlabel[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(path[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mpolygon2asap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_polygon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCell_nucleus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m topilimage \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m     22\u001b[0m np_image\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()),(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36mpolygon2asap\u001b[0;34m(label_polygon, class_list, save_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m             ET\u001b[38;5;241m.\u001b[39mSubElement(coordinates, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinate\u001b[39m\u001b[38;5;124m\"\u001b[39m, Order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(k), X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(label_polygon[i][j][k,\u001b[38;5;241m0\u001b[39m])), Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(label_polygon[i][j][k,\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m     57\u001b[0m tree \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mElementTree(root)\n\u001b[0;32m---> 58\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/xml/etree/ElementTree.py:732\u001b[0m, in \u001b[0;36mElementTree.write\u001b[0;34m(self, file_or_filename, encoding, xml_declaration, default_namespace, method, short_empty_elements)\u001b[0m\n\u001b[1;32m    730\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-ascii\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m enc_lower \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _get_writer(file_or_filename, enc_lower) \u001b[38;5;28;01mas\u001b[39;00m write:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (xml_declaration \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    734\u001b[0m             (xml_declaration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    735\u001b[0m              enc_lower \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-ascii\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124municode\u001b[39m\u001b[38;5;124m\"\u001b[39m))):\n\u001b[1;32m    736\u001b[0m         declared_encoding \u001b[38;5;241m=\u001b[39m encoding\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/contextlib.py:117\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/xml/etree/ElementTree.py:768\u001b[0m, in \u001b[0;36m_get_writer\u001b[0;34m(file_or_filename, encoding)\u001b[0m\n\u001b[1;32m    766\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file_or_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m                \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxmlcharrefreplace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m file\u001b[38;5;241m.\u001b[39mwrite\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/codecs.py:186\u001b[0m, in \u001b[0;36mIncrementalEncoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    An IncrementalEncoder encodes an input in multiple steps. The input can\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    be passed piece by piece to the encode() method. The IncrementalEncoder\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    remembers the state of the encoding process between calls to encode().\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        Creates an IncrementalEncoder instance.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m        for a list of possible values.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m errors\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hovernet.eval()\n",
    "\n",
    "ims = None\n",
    "mask_truth = None\n",
    "mask_pred = None\n",
    "tissue_types = []\n",
    "path_list=[]\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "        # send the data to the GPU\n",
    "        images = data[0].float().to(device)\n",
    "        path=data[2]\n",
    "        label=data[1]\n",
    "        # pass thru network to get predictions\n",
    "        outputs = hovernet(images)\n",
    "        preds_detection = post_process_batch_hovernet(outputs, n_classes=params['n_classes'])\n",
    "        polygon=mask2polygon(preds_detection[0])\n",
    "        label_polygon=[polygon]\n",
    "        save_path=xml_path+label[0]+'/'+os.path.basename(path[0]).split('.')[0]+'.xml'\n",
    "        polygon2asap(label_polygon,['Cell_nucleus'],save_path)\n",
    "        topilimage = torchvision.transforms.ToPILImage()\n",
    "        np_image=np.transpose(np.array(images[0].cpu().detach()),(1,2,0))*255\n",
    "        overlay=np_image*0.5\n",
    "        overlay[...,1]=overlay[...,1]+polygon2mask((1024,1024),polygon)*0.5\n",
    "        overlay=overlay.astype(np.uint8)\n",
    "        Image.fromarray(overlay).save('../../result/nucleus_segmentation/BR/BRNT/overlay/'+os.path.basename(path[0]).split('.')[0]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-14.0767, -14.9838, -11.3555,  ..., -28.8691, -21.2160, -12.4135],\n",
       "          [-15.5685, -16.1467, -10.2698,  ..., -45.1007, -35.6310, -22.1363],\n",
       "          [-13.9661, -13.3854,  -5.5640,  ..., -56.9306, -47.5858, -31.9139],\n",
       "          ...,\n",
       "          [-18.7844, -30.6218, -40.9398,  ..., -41.4631, -44.7059, -39.1300],\n",
       "          [-16.7990, -27.6635, -36.8830,  ..., -29.7192, -32.9398, -29.7399],\n",
       "          [-13.2419, -21.8966, -28.8512,  ..., -20.6159, -22.5458, -20.1176]],\n",
       "\n",
       "         [[-19.2153, -20.1688, -15.8355,  ..., -37.1458, -27.8645, -16.3953],\n",
       "          [-20.8004, -20.9074, -13.5345,  ..., -56.6302, -45.5433, -28.0373],\n",
       "          [-18.9125, -17.4832,  -7.9580,  ..., -71.2951, -59.8589, -40.5357],\n",
       "          ...,\n",
       "          [-24.3693, -38.1385, -51.1389,  ..., -51.1642, -55.3232, -49.3427],\n",
       "          [-21.9192, -34.9343, -46.6135,  ..., -36.5785, -40.9742, -37.3207],\n",
       "          [-17.2304, -27.8681, -36.5023,  ..., -25.2836, -28.4306, -25.0250]]]],\n",
       "       device='cuda:6')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
