{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import albumentations as A\n",
    "from pathSeg.ml.hovernet import HoVerNet, loss_hovernet, post_process_batch_hovernet\n",
    "from pathSeg.ml.utils import dice_score\n",
    "from pathSeg.utils import plot_segmentation\n",
    "import pytorch_model_summary as tms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.io\n",
    "from glob import glob\n",
    "from PIL import Image   \n",
    "from loguru import logger\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda:2\")\n",
    "print(f\"Device:\\t\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':1024,\n",
    "        'lr':1e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'data_path':'../../data/segmentation/qupath/'}\n",
    "\n",
    "tf = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_hv_map(mask):\n",
    "    assert (\n",
    "        mask.ndim == 2\n",
    "    ), f\"Input mask has shape {mask.shape}. Expecting a mask with 2 dimensions (H, W)\"\n",
    "\n",
    "    out = np.zeros((2, mask.shape[0], mask.shape[1]))\n",
    "    # each individual nucleus is ied with a different number\n",
    "    hv_list = list(np.unique(mask))\n",
    "\n",
    "    try:\n",
    "        hv_list.remove(0)  # 0 is background\n",
    "    # TODO: change to specific exception\n",
    "    except Exception:\n",
    "        logger.warning(\n",
    "            \"No pixels with 0 label. This means that there are no background pixels. This may indicate a problem. Ignore this warning if this is expected/intended.\"\n",
    "        )\n",
    "\n",
    "    for hv_id in hv_list:\n",
    "        # get the mask for the nucleus\n",
    "        hv_map = mask == hv_id\n",
    "        hv_map = hv_map.astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(\n",
    "            hv_map, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "\n",
    "        # get center of mass coords\n",
    "        mom = cv2.moments(contours[0])\n",
    "        com_x = mom[\"m10\"] / (mom[\"m00\"] + 1e-6)\n",
    "        com_y = mom[\"m01\"] / (mom[\"m00\"] + 1e-6)\n",
    "        hv_com = (int(com_y), int(com_x))\n",
    "\n",
    "        hv_x_range = np.arange(1, hv_map.shape[1] + 1)\n",
    "        hv_y_range = np.arange(1, hv_map.shape[0] + 1)\n",
    "        # shifting center of pixels grid to hvance center of mass\n",
    "        hv_x_range -= hv_com[1]\n",
    "        hv_y_range -= hv_com[0]\n",
    "\n",
    "        hv_x, hv_y = np.meshgrid(hv_x_range, hv_y_range)\n",
    "\n",
    "        # remove coord outside of hvance\n",
    "        hv_x[hv_map == 0] = 0\n",
    "        hv_y[hv_map == 0] = 0\n",
    "        hv_x = hv_x.astype(\"float32\")\n",
    "        hv_y = hv_y.astype(\"float32\")\n",
    "\n",
    "        # normalize min into -1 scale\n",
    "        if np.min(hv_x) < 0:\n",
    "            hv_x[hv_x < 0] /= -np.amin(hv_x[hv_x < 0])\n",
    "        if np.min(hv_y) < 0:\n",
    "            hv_y[hv_y < 0] /= -np.amin(hv_y[hv_y < 0])\n",
    "        # normalize max into +1 scale\n",
    "        if np.max(hv_x) > 0:\n",
    "            hv_x[hv_x > 0] /= np.amax(hv_x[hv_x > 0])\n",
    "        if np.max(hv_y) > 0:\n",
    "            hv_y[hv_y > 0] /= np.amax(hv_y[hv_y > 0])\n",
    "        \n",
    "        # add to output mask\n",
    "        # this works assuming background is 0, and each pixel is assigned to only one nucleus.\n",
    "        out[0, :, :] += hv_x\n",
    "        out[1, :, :] += hv_y\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self,parmas, images,masks,mat_list):\n",
    "        \n",
    "        self.images = images\n",
    "        self.masks=masks\n",
    "        self.mat_list=mat_list\n",
    "        self.args=parmas\n",
    "        \n",
    "    def trans(self,image,mask,hv_mask):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "            hv_mask = transform(hv_mask)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "            hv_mask = transform(hv_mask)\n",
    "            \n",
    "        return image,mask,hv_mask\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image=self.images[i]\n",
    "        mask=self.masks[i]\n",
    "        hv_mask=self.mat_list[i]\n",
    "        return image,mask,hv_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "transform1=transforms.RandomHorizontalFlip(1)\n",
    "transform2=transforms.RandomVerticalFlip(1)\n",
    "image_list=glob(params['data_path']+'image/*.jpeg')\n",
    "npy_list=[f.replace('image/', 'mask/') for f in image_list]\n",
    "npy_list=[f.replace('.jpeg', '.npy') for f in npy_list]\n",
    "train_image_list,test_image_list,train_mask_list,test_mask_list=train_test_split(image_list,npy_list,test_size=0.2,random_state=30)\n",
    "train_masks=torch.zeros((len(train_mask_list),2,1024,1024))\n",
    "train_images=torch.zeros((len(train_image_list),3,1024,1024))\n",
    "train_hv_mask=torch.zeros((len(train_image_list),2,1024,1024))\n",
    "for i in tqdm(range(len(train_image_list))):\n",
    "    npy_file =np.load(train_mask_list[i]).astype(np.int32)\n",
    "    mask=torch.tensor(npy_file)\n",
    "    train_images[i]=tf(Image.open(image_list[i]).convert('RGB'))\n",
    "    train_masks[i,0,:,:]+=torch.where(mask>0,1,0)\n",
    "    train_masks[i,1,:,:]+=torch.where(mask==0,1,0)\n",
    "    train_hv_mask[i]=torch.tensor(compute_hv_map(npy_file))\n",
    "\n",
    "    \n",
    "test_masks=torch.zeros((len(test_mask_list),2,1024,1024))\n",
    "test_images=torch.zeros((len(test_image_list),3,1024,1024))\n",
    "test_hv_mask=torch.zeros((len(test_image_list),2,1024,1024))\n",
    "for i in tqdm(range(len(test_image_list))):\n",
    "    npy_file =np.load(test_mask_list[i]).astype(np.int32)\n",
    "    mask=torch.tensor(npy_file)\n",
    "    test_images[i]=tf(Image.open(image_list[i]).convert('RGB'))\n",
    "    test_masks[i,0,:,:]+=torch.where(mask>0,1,0)\n",
    "    test_masks[i,1,:,:]+=torch.where(mask==0,1,0)\n",
    "    test_hv_mask[i]=torch.tensor(compute_hv_map(npy_file))\n",
    "    \n",
    "train_dataset=CustomDataset(params,train_images,train_masks,train_hv_mask)\n",
    "test_dataset=CustomDataset(params,test_images,test_masks,test_hv_mask)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)\n",
    "val_dataloader=DataLoader(test_dataset,batch_size=params['batch_size'],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "hovernet = HoVerNet(n_classes=params['n_classes']).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(hovernet.parameters(), lr = params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "# learning rate scheduler to reduce LR by factor of 10 each 25 epochs\n",
    "scheduler = StepLR(opt, step_size=25, gamma=0.1)\n",
    "tms.summary(hovernet, torch.zeros(params['batch_size'],3, params['image_size'], params['image_size']).to(device),print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks, hvs = next(iter(train_dataloader))\n",
    "\n",
    "n = params['batch_size']\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize = (16, 4))\n",
    "\n",
    "cm_mask = copy.copy(cm.get_cmap(\"tab10\"))\n",
    "cm_mask.set_bad(color='white')\n",
    "\n",
    "for i in range(n):\n",
    "    im = images[i, ...].numpy()\n",
    "    ax[ 0].imshow(np.moveaxis(im, 0, 2))\n",
    "    m = masks.argmax(dim=1)[i, ...]\n",
    "    m = np.ma.masked_where(m == 1, m)\n",
    "    ax[ 1].imshow(m,cmap='gray')\n",
    "    ax[ 2].imshow(hvs[i, 0, ...], cmap = 'coolwarm')\n",
    "    ax[ 3].imshow(hvs[i, 1, ...], cmap = 'coolwarm')\n",
    "    \n",
    "for a in ax.ravel(): a.axis(\"off\")\n",
    "for c,v in enumerate([\"H&E Image\", \"Nucleus Types\", \"Horizontal Map\", \"Vertical Map\"]):\n",
    "    ax[c].set_title(v)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = params['epochs']\n",
    "# print performance metrics every n epochs\n",
    "\n",
    "# evaluating performance on a random subset of validation mini-batches\n",
    "# this saves time instead of evaluating on the entire validation set\n",
    "n_minibatch_valid = 10\n",
    "\n",
    "epoch_train_losses = {}\n",
    "epoch_valid_losses = {}\n",
    "epoch_train_dice = {}\n",
    "epoch_valid_dice = {}\n",
    "\n",
    "best_epoch = 0\n",
    "# main training loop\n",
    "for i in range(n_epochs):\n",
    "    minibatch_train_losses = []\n",
    "    minibatch_train_dice = []\n",
    "    \n",
    "    # put model in training mode\n",
    "    hovernet.train()\n",
    "    train_tqdm=tqdm(train_dataloader)\n",
    "    for data in train_tqdm:\n",
    "        # send the data to the GPU\n",
    "        images = data[0].float().to(device)\n",
    "        masks = data[1].to(device)\n",
    "        hv = data[2].float().to(device)\n",
    "        \n",
    "        # zero out gradient\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = hovernet(images)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_hovernet(outputs = outputs, ground_truth = [masks, hv], n_classes=params['n_classes']).to(device)\n",
    "        \n",
    "        # track loss\n",
    "        minibatch_train_losses.append(loss.item())\n",
    "        \n",
    "        # also track dice score to measure performance\n",
    "        preds_detection = post_process_batch_hovernet(outputs, n_classes=params['n_classes'])\n",
    "        truth_binary = masks[:, 0, :, :] == 1\n",
    "        dice = dice_score(preds_detection, truth_binary.cpu().numpy())\n",
    "        minibatch_train_dice.append(dice)\n",
    "        \n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # step optimizer and scheduler\n",
    "        opt.step()\n",
    "        train_tqdm.set_description(f\"train epoch: {i+1}/{n_epochs} loss : {np.mean(minibatch_train_losses):.4f} dice: {np.mean(minibatch_train_dice):.4f}\")\n",
    "    #step LR scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # evaluate on random subset of validation data\n",
    "    hovernet.eval()\n",
    "    minibatch_valid_losses = []\n",
    "    minibatch_valid_dice = []\n",
    "    # randomly choose minibatches for evaluating\n",
    "    minibatch_ix = np.random.choice(range(len(val_dataloader)), replace=True, size=n_minibatch_valid)\n",
    "    with torch.no_grad():\n",
    "        val_tqdm=tqdm(val_dataloader)\n",
    "        for data in val_tqdm:\n",
    "            # send the data to the GPU\n",
    "            images = data[0].float().to(device)\n",
    "            masks = data[1].to(device)\n",
    "            hv = data[2].float().to(device)\n",
    "\n",
    "\n",
    "            # forward pass\n",
    "            outputs = hovernet(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_hovernet(outputs = outputs, ground_truth = [masks, hv], n_classes=params['n_classes']).to(device)\n",
    "\n",
    "            # track loss\n",
    "            minibatch_valid_losses.append(loss.item())\n",
    "\n",
    "            # also track dice score to measure performance\n",
    "            preds_detection= post_process_batch_hovernet(outputs, n_classes=params['n_classes'])\n",
    "            truth_binary = masks[:, 0, :, :] == 1\n",
    "            dice = dice_score(preds_detection, truth_binary.cpu().numpy())\n",
    "            minibatch_valid_dice.append(dice)\n",
    "            val_tqdm.set_description(f\"validation epoch: {i+1}/{n_epochs} loss : {np.mean(minibatch_valid_losses):.4f} dice: {np.mean(minibatch_valid_dice):.4f}\")\n",
    "    # average performance metrics over minibatches\n",
    "    mean_train_loss = np.mean(minibatch_train_losses)\n",
    "    mean_valid_loss = np.mean(minibatch_valid_losses)\n",
    "    mean_train_dice = np.mean(minibatch_train_dice)\n",
    "    mean_valid_dice = np.mean(minibatch_valid_dice)\n",
    "    \n",
    "    # save the model with best performance\n",
    "    if i != 0:\n",
    "        if mean_valid_loss < min(epoch_valid_losses.values()):\n",
    "            best_epoch = i\n",
    "            torch.save(hovernet.state_dict(), f\"../../model/pathSeg/hovernet_binary_qupath_best_perf.pt\")\n",
    "    \n",
    "    # track performance over training epochs\n",
    "    epoch_train_losses.update({i : mean_train_loss})\n",
    "    epoch_valid_losses.update({i : mean_valid_loss})\n",
    "    epoch_train_dice.update({i : mean_train_dice})\n",
    "    epoch_valid_dice.update({i : mean_valid_dice})\n",
    "    \n",
    "    # print(f\"Epoch {i+1}/{n_epochs} training loss: {np.round(mean_train_loss, 4)} validation loss: {np.round(mean_valid_loss, 4)} training dice: {np.round(mean_train_dice, 4)} validation dice: {np.round(mean_valid_dice, 4)}\")\n",
    "# save fully trained model\n",
    "torch.save(hovernet.state_dict(), f\"../../model/pathSeg/hovernet_binary_qupath_fully_trained.pt\")\n",
    "print(f\"\\nEpoch with best validation performance: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(nrows=1, ncols=2, figsize = (10, 4))\n",
    "\n",
    "ax[0].plot(epoch_train_losses.keys(), epoch_train_losses.values(), label = \"Train\")\n",
    "ax[0].plot(epoch_valid_losses.keys(), epoch_valid_losses.values(), label = \"Validation\")\n",
    "ax[0].scatter(x=best_epoch, y=epoch_valid_losses[best_epoch], label = \"Best Model\",\n",
    "              color = \"green\", marker=\"*\")\n",
    "ax[0].set_title(\"Training: Loss\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch_train_dice.keys(), epoch_train_dice.values(), label = \"Train\")\n",
    "ax[1].plot(epoch_valid_dice.keys(), epoch_valid_dice.values(), label = \"Validation\")\n",
    "ax[1].scatter(x=best_epoch, y=epoch_valid_dice[best_epoch], label = \"Best Model\",\n",
    "              color = \"green\", marker=\"*\")\n",
    "ax[1].set_title(\"Training: Dice Score\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"Dice Score\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"../../model/pathSeg/hovernet_binary_best_perf.pt\")\n",
    "hovernet.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hovernet.eval()\n",
    "\n",
    "ims = None\n",
    "mask_truth = None\n",
    "mask_pred = None\n",
    "tissue_types = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(val_dataloader)):\n",
    "        # send the data to the GPU\n",
    "        images = data[0].float().to(device)\n",
    "        masks = data[1].to(device)\n",
    "        hv = data[2].float().to(device)\n",
    "        truth_binary = masks[:, 0, :, :] == 1\n",
    "\n",
    "        # pass thru network to get predictions\n",
    "        outputs = hovernet(images)\n",
    "        preds_detection = post_process_batch_hovernet(outputs, n_classes=params['n_classes'])\n",
    "        \n",
    "        if i == 0:\n",
    "            ims = data[0].numpy()\n",
    "            mask_truth = data[1].numpy()\n",
    "            mask_pred = preds_detection\n",
    "\n",
    "        else:\n",
    "            ims = np.concatenate([ims, data[0].numpy()], axis=0)\n",
    "            mask_truth = np.concatenate([mask_truth, data[1].numpy()], axis=0)\n",
    "            mask_pred = np.concatenate([mask_pred, preds_detection], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = np.moveaxis(ims, 1, 3)\n",
    "n = 8\n",
    "mask_truth=mask_truth[:,0,:,:]==1\n",
    "mask_truth=mask_truth[:,np.newaxis,:,:] \n",
    "mask_pred=mask_pred[:,np.newaxis,:,:] \n",
    "ix = np.random.choice(np.arange(7), size = n)\n",
    "fig, ax = plt.subplots(nrows = n, ncols = 3, figsize = (8, 2.5*n))\n",
    "for i, index in enumerate(ix):\n",
    "    ax[i, 0].imshow(ims[index, ...])\n",
    "    ax[i, 1].imshow(ims[index, ...])\n",
    "    ax[i, 2].imshow(ims[index, ...])\n",
    "    plot_segmentation(ax = ax[i, 1], masks = mask_pred[index, ...])\n",
    "    plot_segmentation(ax = ax[i, 2], masks = mask_truth[index, ...])\n",
    "        \n",
    "for a in ax.ravel(): \n",
    "    a.get_xaxis().set_ticks([])\n",
    "    a.get_yaxis().set_ticks([])\n",
    "ax[0, 0].set_title(\"image\")\n",
    "ax[0, 1].set_title(\"Prediction\")\n",
    "ax[0, 2].set_title(\"Truth\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
