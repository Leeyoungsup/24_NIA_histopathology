{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy.ndimage import gaussian_filter\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=1\n",
    "img_size=1024\n",
    "class_list=['NT_epithelial','NT_immune','NT_stroma','TP_in_situ','TP_invasive']\n",
    "csv_path =\"../../data/BRIL 2차 정제 완료 리스트.csv\"\n",
    "\n",
    "tf = ToTensor()\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "    \n",
    "\n",
    "def binary_mask_to_polygon(binary_mask):\n",
    "    # binary_mask는 2차원 numpy array여야 합니다.\n",
    "    # Contours를 찾습니다.\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [cnt for cnt in contours if cv2.contourArea(cnt) >= 1000]\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # 각 contour를 polygon으로 변환\n",
    "        if len(contour) >= 3:  # 유효한 polygon을 만들기 위해서 최소한 3개의 점이 필요합니다.\n",
    "            poly = Polygon(shell=[(point[0][0], point[0][1]) for point in contour])\n",
    "            polygons.append(poly)\n",
    "    \n",
    "    if len(polygons) > 1:\n",
    "        # 여러 개의 polygon이 있을 경우 MultiPolygon으로 변환\n",
    "        return MultiPolygon(polygons)\n",
    "    elif len(polygons) == 1:\n",
    "        return MultiPolygon(polygons)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def mask2polygon(mask):\n",
    "    NT_stroma_poly=binary_mask_to_polygon(mask[...,2])\n",
    "    NT_immune_poly=binary_mask_to_polygon(mask[...,1])\n",
    "    NT_epithelial_poly=binary_mask_to_polygon(mask[...,0])\n",
    "    TP_in_situ_poly=binary_mask_to_polygon(mask[...,3])\n",
    "    TP_invasive_poly=binary_mask_to_polygon(mask[...,4])\n",
    "\n",
    "    NT_epithelial_polygon_arrays = []\n",
    "    NT_immune_polygon_arrays = []\n",
    "    NT_stroma_polygon_arrays = []\n",
    "    TP_invasive_polygon_arrays = []\n",
    "    TP_in_situ_polygon_arrays = []\n",
    "\n",
    "    if TP_invasive_poly!=None:\n",
    "        for polygon in TP_invasive_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            TP_invasive_polygon_arrays.append(exterior_coords)\n",
    "\n",
    "    if NT_stroma_poly!=None:\n",
    "        for polygon in NT_stroma_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            NT_stroma_polygon_arrays.append(exterior_coords)\n",
    "\n",
    "    if NT_immune_poly!=None:\n",
    "        for polygon in NT_immune_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            NT_immune_polygon_arrays.append(exterior_coords)\n",
    "            \n",
    "    if NT_epithelial_poly!=None:\n",
    "        for polygon in NT_epithelial_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            NT_epithelial_polygon_arrays.append(exterior_coords)\n",
    "            \n",
    "    if TP_in_situ_poly!=None:\n",
    "        for polygon in TP_in_situ_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            TP_in_situ_polygon_arrays.append(exterior_coords)\n",
    "            \n",
    "    return  NT_epithelial_polygon_arrays,NT_immune_polygon_arrays,NT_stroma_polygon_arrays,TP_in_situ_polygon_arrays,TP_invasive_polygon_arrays\n",
    "\n",
    "def polygon2asap(label_polygon,class_list,save_path):\n",
    "    # 루트 엘리먼트 생성\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    # Annotations 엘리먼트 생성 및 루트에 추가\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    for i in range(len(label_polygon)):\n",
    "        \n",
    "        for j in range(len(label_polygon[i])):\n",
    "            annotation = ET.SubElement(annotations, \"Annotation\", Name=class_list[i], Type=\"Polygon\", PartOfGroup=\"None\", Color=\"#F4FA58\")\n",
    "            coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "            for k in range(len(label_polygon[i][j])):\n",
    "                ET.SubElement(coordinates, \"Coordinate\", Order=str(k), X=str(float(label_polygon[i][j][k,0])), Y=str(float(label_polygon[i][j][k,1])))\n",
    "            \n",
    "            \n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(save_path)\n",
    "    \n",
    "def smooth_multiclass_mask(mask, sigma=2):\n",
    "    \"\"\"\n",
    "    다중 클래스 세그멘테이션 마스크를 부드럽게 만드는 함수입니다.\n",
    "\n",
    "    Parameters:\n",
    "        mask (np.ndarray): softmax를 적용한 다중 클래스 세그멘테이션 마스크.\n",
    "                           shape은 (H, W, num_classes)이어야 합니다.\n",
    "        sigma (float): Gaussian 블러의 표준 편차. 값이 클수록 마스크가 더 부드럽게 됩니다.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 부드럽게 처리된 softmax 마스크.\n",
    "    \"\"\"\n",
    "    # 각 클래스 채널에 대해 Gaussian 블러 적용\n",
    "    smooth_mask = np.zeros_like(mask)\n",
    "    for i in range(mask.shape[-1]):\n",
    "        smooth_mask[:, :, i] = gaussian_filter(mask[:, :, i], sigma=sigma)\n",
    "\n",
    "    # 각 픽셀에 대해 softmax 재적용\n",
    "    smooth_mask = np.exp(smooth_mask) / np.sum(np.exp(smooth_mask), axis=-1, keepdims=True)\n",
    "\n",
    "    return smooth_mask\n",
    "def polygon2mask(image_shape, NT_epithelial_polygons, NT_immune_polygons, NT_stroma_polygons, TP_in_situ_polygons, TP_invasive_polygons):\n",
    "    # 빈 마스크 생성 (모든 채널을 0으로 초기화)\n",
    "    NT_epithelial_mask = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    NT_immune_mask = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    NT_stroma_mask = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    TP_in_situ_mask = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    TP_invasive_mask = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)\n",
    "    mask=np.zeros((image_shape[0], image_shape[1], 5), dtype=np.uint8)\n",
    "    \n",
    "    # 각 다각형 리스트를 순회하면서 마스크의 해당 채널에 채우기\n",
    "    for polygon in NT_epithelial_polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(NT_epithelial_mask, [polygon], 255)\n",
    "        \n",
    "    for polygon in NT_immune_polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(NT_immune_mask, [polygon], 255)\n",
    "        \n",
    "    for polygon in NT_stroma_polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)  # 좌표를 int32로 변환\n",
    "        cv2.fillPoly(NT_stroma_mask, [polygon], 255)\n",
    "        \n",
    "    for polygon in TP_in_situ_polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(TP_in_situ_mask, [polygon], 255)\n",
    "        \n",
    "    for polygon in TP_invasive_polygons:\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(TP_invasive_mask, [polygon], 255)\n",
    "    mask[...,0]+=NT_epithelial_mask\n",
    "    mask[...,1]+=NT_immune_mask\n",
    "    mask[...,2]+=NT_stroma_mask\n",
    "    mask[...,3]+=TP_in_situ_mask\n",
    "    mask[...,4]+=TP_invasive_mask\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7635/7635 [01:13<00:00, 104.10it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_data=pd.read_csv(csv_path)\n",
    "img_path='../../data/NIA/**/'\n",
    "xml_path='../../result/area_segmentation/BRIL/'\n",
    "image_list=[]\n",
    "category_list=[]\n",
    "\n",
    "for i in tqdm(range(len(pd_data))):\n",
    "    image_list.append(glob(img_path+pd_data['file_name'][i])[0])\n",
    "    category_list.append(pd_data['category'][i])\n",
    "\n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        self.tf= ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path=self.img_path[idx]\n",
    "        image=self.tf(Image.open(self.img_path[idx]).resize((img_size,img_size)))\n",
    "        label=self.label[idx]\n",
    "        return image,label,path\n",
    "\n",
    "dataset = CustomDataset(image_list, category_list)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1800120/826017286.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  NT_epithelial_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[0]+'.pt',map_location=device))\n",
      "/tmp/ipykernel_1800120/826017286.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  NT_immune_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[1]+'.pt',map_location=device))\n",
      "/tmp/ipykernel_1800120/826017286.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  NT_stroma_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[2]+'.pt',map_location=device))\n",
      "/tmp/ipykernel_1800120/826017286.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  TP_in_situ_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[3]+'.pt',map_location=device))\n",
      "/tmp/ipykernel_1800120/826017286.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  TP_invasive_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[4]+'.pt',map_location=device))\n"
     ]
    }
   ],
   "source": [
    "NT_epithelial_model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "NT_immune_model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "NT_stroma_model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "TP_in_situ_model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "TP_invasive_model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "\n",
    "def dice_loss(pred, target, num_classes=len(class_list)):\n",
    "    smooth = 1e-6\n",
    "    dice_per_class = torch.zeros((len(pred),num_classes)).to(pred.device)\n",
    "    pred=F.softmax(pred,dim=1)\n",
    "    for i in range(len(pred)):\n",
    "        for class_id in range(num_classes):\n",
    "            pred_class = pred[i, class_id, ...]\n",
    "            target_class = target[i, class_id, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * target_class)\n",
    "            A_sum = torch.sum(pred_class * pred_class)\n",
    "            B_sum = torch.sum(target_class * target_class)\n",
    "            dice_per_class[i,class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return 1-dice_per_class\n",
    "\n",
    "\n",
    "NT_epithelial_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[0]+'.pt',map_location=device))\n",
    "NT_immune_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[1]+'.pt',map_location=device))\n",
    "NT_stroma_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[2]+'.pt',map_location=device))\n",
    "TP_in_situ_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[3]+'.pt',map_location=device))\n",
    "TP_invasive_model.load_state_dict(torch.load('../../model/areaSeg/BR_'+class_list[4]+'.pt',map_location=device))\n",
    "model_list=[NT_epithelial_model,NT_immune_model,NT_stroma_model,TP_in_situ_model,TP_invasive_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7635 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7635/7635 [1:05:11<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "class_weight=[3,2,4,0,1]\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "k1 = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "train_loss_list=[]\n",
    "val_loss_list=np.zeros((len(dataloader),5))\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "MIN_loss=5000\n",
    "metrics = defaultdict(float)\n",
    "for i in range(len(model_list)):\n",
    "    model_list[i].eval()\n",
    "count=0\n",
    "val_running_loss=0.0\n",
    "acc_loss=0\n",
    "with torch.no_grad():\n",
    "    for x,label,path in tqdm(dataloader):\n",
    "        count+=1\n",
    "        label=label[0]\n",
    "        path=path[0]\n",
    "        x=x.to(device).float()\n",
    "        predict=torch.zeros((1,5,1024,1024)).to(device)\n",
    "        for i in class_weight:\n",
    "            model=model_list[i]\n",
    "            predict1 = model(x).to(device)\n",
    "            predict_index=torch.where(F.softmax(predict1, dim=1)[0,1]>=0.6)\n",
    "            for j in range(5):\n",
    "                predict[0,j][predict_index]=0.\n",
    "            predict[0,i][predict_index]=1.\n",
    "        x=x.to('cpu')\n",
    "        \n",
    "        mask1=np.zeros((img_size,img_size,3))\n",
    "        pred_softmax=np.array(predict.cpu())\n",
    "        mask=np.zeros((img_size,img_size,5),dtype=np.uint8)\n",
    "        mask[...,0]=cv2.morphologyEx(pred_softmax[0][0], cv2.MORPH_OPEN, k)*255\n",
    "        mask[...,1]=cv2.morphologyEx(pred_softmax[0][1], cv2.MORPH_OPEN, k)*255\n",
    "        mask[...,2]=cv2.morphologyEx(pred_softmax[0][2], cv2.MORPH_OPEN, k)*255\n",
    "        mask[...,3]=cv2.morphologyEx(pred_softmax[0][3], cv2.MORPH_OPEN, k)*255\n",
    "        mask[...,4]=cv2.morphologyEx(pred_softmax[0][4], cv2.MORPH_OPEN, k)*255\n",
    "        # mask1=smooth_multiclass_mask(mask)\n",
    "        # mask[...,0]=np.where(mask1.argmax(axis=2)==0,255,0)\n",
    "        # mask[...,1]=np.where(mask1.argmax(axis=2)==1,255,0)\n",
    "        # mask[...,2]=np.where(mask1.argmax(axis=2)==2,255,0)\n",
    "        # mask[...,3]=np.where(mask1.argmax(axis=2)==3,255,0)\n",
    "        NT_epithelial_polygons,NT_immune_polygons,NT_stroma_polygons,TP_in_situ_polygons,TP_invasive_polygons=mask2polygon(mask)\n",
    "        label_polygon=[NT_epithelial_polygons,NT_immune_polygons,NT_stroma_polygons,TP_in_situ_polygons,TP_invasive_polygons]\n",
    "        save_path=xml_path+label+'/'+os.path.basename(path).split('.')[0]+'.xml'\n",
    "        polygon2asap(label_polygon,class_list,save_path)\n",
    "        mask2=polygon2mask((1024,1024),NT_epithelial_polygons,NT_immune_polygons,NT_stroma_polygons,TP_in_situ_polygons,TP_invasive_polygons)\n",
    "        mask1[...,0]+=mask2[...,0]\n",
    "        mask1[...,1]+=mask2[...,1]\n",
    "        mask1[...,2]+=mask2[...,2]\n",
    "        mask1[...,1]+=mask2[...,3]\n",
    "        mask1[...,2]+=mask2[...,3]\n",
    "        mask1[...,0]+=mask2[...,4]\n",
    "        mask1[...,1]+=mask2[...,4]\n",
    "        image=x.squeeze().permute(1,2,0).numpy()\n",
    "        image=image*255\n",
    "        overlay=image*0.7+mask1*0.3\n",
    "        overlay=overlay.astype(np.uint8)\n",
    "        overlay=Image.fromarray(overlay)\n",
    "        overlay.save('../../result/area_segmentation/BRIL/overlay/'+os.path.basename(path))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0],\n",
       "        [  0,   0, 255,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'fillPoly'\n> Overload resolution failed:\n>  - Layout of the output array img is incompatible with cv::Mat\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pts1 \u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(NT_stroma_polygons[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m5\u001b[39m),dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillPoly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'fillPoly'\n> Overload resolution failed:\n>  - Layout of the output array img is incompatible with cv::Mat\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "source": [
    "pts1 =np.array(NT_stroma_polygons[0], dtype=np.int32)\n",
    "img = np.zeros((1024,1024,5),dtype=np.uint8)\n",
    "cv2.fillPoly(img[...,0],[pts1],color=(255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[...,0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
