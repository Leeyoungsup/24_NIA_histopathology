{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=1\n",
    "img_size=1024\n",
    "class_list=['NT_immune', 'NT_stroma', 'TP_in_situ']\n",
    "class_nm='NT_immune'\n",
    "csv_path =\"../../data/BRDC 2차 정제 완료 리스트.csv\"\n",
    "\n",
    "tf = ToTensor()\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "    \n",
    "\n",
    "def binary_mask_to_polygon(binary_mask):\n",
    "    # binary_mask는 2차원 numpy array여야 합니다.\n",
    "    # Contours를 찾습니다.\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # 각 contour를 polygon으로 변환\n",
    "        if len(contour) >= 3:  # 유효한 polygon을 만들기 위해서 최소한 3개의 점이 필요합니다.\n",
    "            poly = Polygon(shell=[(point[0][0], point[0][1]) for point in contour])\n",
    "            polygons.append(poly)\n",
    "    \n",
    "    if len(polygons) > 1:\n",
    "        # 여러 개의 polygon이 있을 경우 MultiPolygon으로 변환\n",
    "        return MultiPolygon(polygons)\n",
    "    elif len(polygons) == 1:\n",
    "        return MultiPolygon(polygons)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def mask2polygon(mask):\n",
    "    TP_in_situ_poly=binary_mask_to_polygon(mask[...,2])\n",
    "    NT_stroma_poly=binary_mask_to_polygon(mask[...,1])\n",
    "    NT_immune_poly=binary_mask_to_polygon(mask[...,0])\n",
    "\n",
    "    TP_in_situ_polygon_arrays = []\n",
    "    NT_stroma_polygon_arrays = []\n",
    "    NT_immune_polygon_arrays = []\n",
    "\n",
    "    if TP_in_situ_poly!=None:\n",
    "        for polygon in TP_in_situ_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            TP_in_situ_polygon_arrays.append(exterior_coords)\n",
    "\n",
    "    if NT_stroma_poly!=None:\n",
    "        for polygon in NT_stroma_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            NT_stroma_polygon_arrays.append(exterior_coords)\n",
    "\n",
    "    if NT_immune_poly!=None:\n",
    "        for polygon in NT_immune_poly.geoms:\n",
    "            exterior_coords = np.array(polygon.exterior.coords)\n",
    "            NT_immune_polygon_arrays.append(exterior_coords)\n",
    "    return  NT_immune_polygon_arrays,NT_stroma_polygon_arrays,TP_in_situ_polygon_arrays\n",
    "\n",
    "def polygon2asap(label_polygon,class_list,save_path):\n",
    "    # 루트 엘리먼트 생성\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    # Annotations 엘리먼트 생성 및 루트에 추가\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    for i in range(len(label_polygon)):\n",
    "        \n",
    "        for j in range(len(label_polygon[i])):\n",
    "            annotation = ET.SubElement(annotations, \"Annotation\", Name=class_list[i], Type=\"Polygon\", PartOfGroup=\"None\", Color=\"#F4FA58\")\n",
    "            coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "            for k in range(len(label_polygon[i][j])):\n",
    "                ET.SubElement(coordinates, \"Coordinate\", Order=str(k), X=str(float(label_polygon[i][j][k,1])), Y=str(float(label_polygon[i][j][k,0])))\n",
    "            \n",
    "            \n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data=pd.read_csv(csv_path)\n",
    "img_path='../../data/NIA/BRDC/'\n",
    "json_path='../../result/area_segmentation/json/BRDC/'\n",
    "xml_path='../../result/area_segmentation/xml/BRDC/'\n",
    "image_list=[]\n",
    "category_list=[]\n",
    "\n",
    "for i in range(len(pd_data)):\n",
    "    image_list.append(img_path+pd_data['file_name'][i])\n",
    "    category_list.append(pd_data['category'][i])\n",
    "\n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        self.tf= ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path=self.img_path[idx]\n",
    "        image=self.tf(Image.open(self.img_path[idx]))\n",
    "        label=self.label[idx]\n",
    "        return image,label,path\n",
    "\n",
    "dataset = CustomDataset(image_list, category_list)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NT_immune_model = smp.MAnet(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "NT_stroma_model = smp.MAnet(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "TP_in_situ_model = smp.MAnet(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "def dice_loss(pred, target, num_classes=2):\n",
    "    smooth = 1e-6\n",
    "    dice_per_class = torch.zeros((len(pred),num_classes)).to(pred.device)\n",
    "    pred=F.softmax(pred,dim=1)\n",
    "    for i in range(len(pred)):\n",
    "        for class_id in range(num_classes):\n",
    "            pred_class = pred[i, class_id, ...]\n",
    "            target_class = target[i, class_id, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * target_class)\n",
    "            A_sum = torch.sum(pred_class * pred_class)\n",
    "            B_sum = torch.sum(target_class * target_class)\n",
    "            dice_per_class[i,class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return 1-dice_per_class\n",
    "\n",
    "NT_immune_model.load_state_dict(torch.load('../../model/areaSeg/'+class_list[0]+'_callback.pt'))\n",
    "NT_stroma_model.load_state_dict(torch.load('../../model/areaSeg/'+class_list[1]+'_callback.pt'))\n",
    "TP_in_situ_model.load_state_dict(torch.load('../../model/areaSeg/'+class_list[2]+'_callback.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "k = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "MIN_loss=5000\n",
    "metrics = defaultdict(float)\n",
    "NT_immune_model.eval()\n",
    "NT_stroma_model.eval()\n",
    "TP_in_situ_model.eval()\n",
    "count=0\n",
    "val_running_loss=0.0\n",
    "acc_loss=0\n",
    "with torch.no_grad():\n",
    "    for x, label,path in tqdm(dataloader):\n",
    "        label= label[0]\n",
    "        path=path[0]\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        NT_immune_predict = NT_immune_model(x).to(device)\n",
    "        NT_stroma_predict = NT_stroma_model(x).to(device)\n",
    "        TP_in_situ_predict = TP_in_situ_model(x).to(device)\n",
    "        x=x.to('cpu')\n",
    "        \n",
    "        NT_immune_pred_softmax = F.softmax(NT_immune_predict, dim=1).cpu()\n",
    "        NT_stroma_pred_softmax = F.softmax(NT_stroma_predict, dim=1).cpu()\n",
    "        TP_in_situ_pred_softmax = F.softmax(TP_in_situ_predict, dim=1).cpu()\n",
    "        mask=np.zeros((img_size,img_size,3),dtype=np.uint8)\n",
    "        NT_immune_mask=cv2.morphologyEx(np.array(torch.where(NT_immune_pred_softmax.argmax(dim=1)==1,255,0).squeeze()).astype('uint8'), cv2.MORPH_OPEN, k)\n",
    "        NT_stroma_mask=cv2.morphologyEx(np.array(torch.where(NT_stroma_pred_softmax.argmax(dim=1)==1,255,0).squeeze()).astype('uint8'), cv2.MORPH_OPEN, k)\n",
    "        TP_in_situ_mask=cv2.morphologyEx(np.array(torch.where(TP_in_situ_pred_softmax.argmax(dim=1)==1,255,0).squeeze()).astype('uint8'), cv2.MORPH_OPEN, k)\n",
    "        NT_stroma_mask=np.where((NT_stroma_mask.astype('int64')-NT_immune_mask-TP_in_situ_mask).astype('int64')>0,255,0).astype('uint8')\n",
    "        NT_immune_mask=np.where((NT_immune_mask.astype('int64')-TP_in_situ_mask)>0,255,0).astype('uint8')\n",
    "    \n",
    "        mask[...,0]=NT_immune_mask\n",
    "        mask[...,1]=NT_stroma_mask\n",
    "        mask[...,2]=TP_in_situ_mask\n",
    "        NT_immune_polygons,NT_stroma_polygons,TP_in_situ_polygons=mask2polygon(mask)\n",
    "        label_polygon=[NT_immune_polygons,NT_stroma_polygons,TP_in_situ_polygons]\n",
    "        save_path=xml_path+label+'/'+os.path.basename(path).split('.')[0]+'.xml'\n",
    "        polygon2asap(label_polygon,class_list,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NIA6_R_BRDC_BRCA-IS-00069-S-TP-02_27_39'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
