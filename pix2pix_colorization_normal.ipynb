{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from glob import glob\n",
    "from torchinfo import summary\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp  # Mixed Precision Training\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\", 5)\n",
    "print(f\"Device:\\t\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_size': 1024,\n",
    "          'lr': 2e-5,\n",
    "          'batch_size': 8,  # 배치 사이즈를 줄여 메모리 부담을 줄임\n",
    "          'epochs': 1000,\n",
    "          'n_classes': None,\n",
    "          'data_path': '../../data/normalization_type/Notstandard/',\n",
    "          'image_count': 5000,\n",
    "          'gradient_accumulation_steps': 2,  # Gradient Accumulation 설정\n",
    "          }\n",
    "tf = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "\n",
    "    def __init__(self, parmas, L_image, RGB_image):\n",
    "\n",
    "        self.L_images = L_image\n",
    "        self.args = parmas\n",
    "        self.RGB_image = RGB_image\n",
    "\n",
    "    def trans(self, L_image,RGB_image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            L_image = transform(L_image)\n",
    "            RGB_image=transform(RGB_image)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            L_image = transform(L_image)\n",
    "            RGB_image=transform(RGB_image)\n",
    "\n",
    "        return L_image,RGB_image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        L_image = self.L_images[index]\n",
    "        RGB_image = self.RGB_image[index]\n",
    "        L_image ,RGB_image = self.trans(L_image,RGB_image)\n",
    "        return RGB_image,L_image \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.L_images)\n",
    "\n",
    "image_list = glob(params['data_path']+'*.jpeg')\n",
    "RGB_image_list=[f.replace('/Notstandard', '/Notstandard_r') for f in image_list]\n",
    "L_images=torch.zeros((len(image_list),3,params['image_size'],params['image_size']))\n",
    "RGB_images=torch.zeros((len(image_list),3,params['image_size'],params['image_size']))\n",
    "for i in tqdm(range(len(image_list))):\n",
    "    image=Image.open(image_list[i])\n",
    "    L_images[i]=tf(image.convert('L').convert('RGB').resize((params['image_size'], params['image_size'])))*2-1\n",
    "    image=Image.open(RGB_image_list[i])\n",
    "    RGB_images[i]=tf(image.convert('RGB').resize((params['image_size'], params['image_size'])))*2-1\n",
    "train_dataset = CustomDataset(params, L_images, RGB_images)\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, batch_size=params['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net 아키텍처의 다운 샘플링(Down Sampling) 모듈\n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        # 너비와 높이가 2배씩 감소\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# U-Net 아키텍처의 업 샘플링(Up Sampling) 모듈: Skip Connection 입력 사용\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        # ConvTranspose2d 대신 Upsample과 Conv2d 사용\n",
    "        layers = [nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "                  nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.InstanceNorm2d(out_channels),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)  # 채널 레벨에서 합치기\n",
    "        return x\n",
    "\n",
    "\n",
    "# U-Net 생성자(Generator) 아키텍처\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)  # 출력: [64 x 512 x 512]\n",
    "        self.down2 = UNetDown(64, 128)                           # 출력: [128 x 256 x 256]\n",
    "        self.down3 = UNetDown(128, 256)                          # 출력: [256 x 128 x 128]\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)             # 출력: [512 x 64 x 64]\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)             # 출력: [512 x 32 x 32]\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5)             # 출력: [512 x 16 x 16]\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5)             # 출력: [512 x 8 x 8]\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)  # 출력: [512 x 4 x 4]\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)                 # 출력: [1024 x 8 x 8]\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)                # 출력: [1024 x 16 x 16]\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5)                # 출력: [1024 x 32 x 32]\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.5)                # 출력: [1024 x 64 x 64]\n",
    "        self.up5 = UNetUp(1024, 256)                             # 출력: [512 x 128 x 128]\n",
    "        self.up6 = UNetUp(512, 128)                              # 출력: [256 x 256 x 256]\n",
    "        self.up7 = UNetUp(256, 64)                               # 출력: [128 x 512 x 512]\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),  # 출력: [128 x 1024 x 1024]\n",
    "            nn.Conv2d(128, out_channels, kernel_size=3, stride=1, padding=1),  # 출력: [3 x 1024 x 1024]\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)\n",
    "\n",
    "\n",
    "# U-Net 판별자(Discriminator) 아키텍처\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_channels, out_channels, normalization=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),  # 출력: [64 x 512 x 512]\n",
    "            *discriminator_block(64, 128),                                  # 출력: [128 x 256 x 256]\n",
    "            *discriminator_block(128, 256),                                 # 출력: [256 x 128 x 128]\n",
    "            *discriminator_block(256, 512),                                 # 출력: [512 x 64 x 64]\n",
    "            *discriminator_block(512, 512),                                 # 출력: [512 x 32 x 32]\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, padding=1, bias=False)         # 출력: [1 x 32 x 32]\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = amp.GradScaler()\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "generator = GeneratorUNet()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# 가중치(weights) 초기화\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "criterion_GAN.to(device)\n",
    "criterion_pixelwise.to(device)\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 2e-5\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "# summary(generator, input_size=(params['batch_size'], 3, params['image_size'], params['image_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560/560 [03:09<00:00,  2.96it/s, epoch=1, D loss: =0.254, G pixel loss: =0.0457, adv loss: =0.0518]\n",
      "100%|██████████| 560/560 [03:09<00:00,  2.95it/s, epoch=2, D loss: =0.254, G pixel loss: =0.0456, adv loss: =0.0517]\n",
      "100%|██████████| 560/560 [03:07<00:00,  2.99it/s, epoch=3, D loss: =0.254, G pixel loss: =0.0456, adv loss: =0.0517]\n",
      "100%|██████████| 560/560 [03:08<00:00,  2.98it/s, epoch=4, D loss: =0.254, G pixel loss: =0.0455, adv loss: =0.0518]\n",
      "100%|██████████| 560/560 [03:09<00:00,  2.95it/s, epoch=5, D loss: =0.253, G pixel loss: =0.0454, adv loss: =0.0522]\n",
      "100%|██████████| 560/560 [03:08<00:00,  2.97it/s, epoch=6, D loss: =0.244, G pixel loss: =0.0454, adv loss: =0.0572]\n",
      "100%|██████████| 560/560 [03:08<00:00,  2.98it/s, epoch=7, D loss: =0.231, G pixel loss: =0.0454, adv loss: =0.0644]\n",
      "100%|██████████| 560/560 [03:09<00:00,  2.95it/s, epoch=8, D loss: =0.22, G pixel loss: =0.0453, adv loss: =0.0705] \n",
      "100%|██████████| 560/560 [03:08<00:00,  2.97it/s, epoch=9, D loss: =0.211, G pixel loss: =0.0452, adv loss: =0.0751]\n",
      "100%|██████████| 560/560 [03:08<00:00,  2.98it/s, epoch=10, D loss: =0.204, G pixel loss: =0.0451, adv loss: =0.0787]\n",
      "100%|██████████| 560/560 [03:07<00:00,  2.99it/s, epoch=11, D loss: =0.199, G pixel loss: =0.0451, adv loss: =0.0814]\n",
      "100%|██████████| 560/560 [03:07<00:00,  2.98it/s, epoch=12, D loss: =0.197, G pixel loss: =0.0449, adv loss: =0.0824]\n",
      "100%|██████████| 560/560 [04:30<00:00,  2.07it/s, epoch=13, D loss: =0.192, G pixel loss: =0.0449, adv loss: =0.0848]\n",
      "100%|██████████| 560/560 [04:44<00:00,  1.97it/s, epoch=14, D loss: =0.191, G pixel loss: =0.0448, adv loss: =0.0853]\n",
      "100%|██████████| 560/560 [04:52<00:00,  1.91it/s, epoch=15, D loss: =0.189, G pixel loss: =0.0447, adv loss: =0.0863]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=16, D loss: =0.188, G pixel loss: =0.0446, adv loss: =0.0872]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=17, D loss: =0.187, G pixel loss: =0.0445, adv loss: =0.0877]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=18, D loss: =0.186, G pixel loss: =0.0444, adv loss: =0.0879]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=19, D loss: =0.187, G pixel loss: =0.0443, adv loss: =0.0877]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.88it/s, epoch=20, D loss: =0.185, G pixel loss: =0.0442, adv loss: =0.0887]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=21, D loss: =0.186, G pixel loss: =0.0441, adv loss: =0.0884]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=22, D loss: =0.184, G pixel loss: =0.0441, adv loss: =0.089] \n",
      "100%|██████████| 560/560 [04:55<00:00,  1.90it/s, epoch=23, D loss: =0.184, G pixel loss: =0.044, adv loss: =0.0891] \n",
      "100%|██████████| 560/560 [04:52<00:00,  1.91it/s, epoch=24, D loss: =0.185, G pixel loss: =0.0439, adv loss: =0.0886]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=25, D loss: =0.183, G pixel loss: =0.0439, adv loss: =0.0895]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=26, D loss: =0.183, G pixel loss: =0.0438, adv loss: =0.0896]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=27, D loss: =0.206, G pixel loss: =0.0437, adv loss: =0.0779]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=28, D loss: =0.2, G pixel loss: =0.0437, adv loss: =0.0808]  \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=29, D loss: =0.19, G pixel loss: =0.0437, adv loss: =0.0859] \n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=30, D loss: =0.191, G pixel loss: =0.0436, adv loss: =0.0854]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=31, D loss: =0.186, G pixel loss: =0.0435, adv loss: =0.088] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=32, D loss: =0.185, G pixel loss: =0.0435, adv loss: =0.0885]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=33, D loss: =0.184, G pixel loss: =0.0434, adv loss: =0.0889]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=34, D loss: =0.187, G pixel loss: =0.0433, adv loss: =0.0878]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.88it/s, epoch=35, D loss: =0.184, G pixel loss: =0.0433, adv loss: =0.0888]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=36, D loss: =0.184, G pixel loss: =0.0432, adv loss: =0.0892]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=37, D loss: =0.183, G pixel loss: =0.0432, adv loss: =0.0894]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=38, D loss: =0.183, G pixel loss: =0.0431, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=39, D loss: =0.188, G pixel loss: =0.0431, adv loss: =0.0871]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=40, D loss: =0.184, G pixel loss: =0.043, adv loss: =0.0891] \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=41, D loss: =0.183, G pixel loss: =0.043, adv loss: =0.0896] \n",
      "100%|██████████| 560/560 [04:49<00:00,  1.93it/s, epoch=42, D loss: =0.189, G pixel loss: =0.0429, adv loss: =0.0865]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.88it/s, epoch=43, D loss: =0.183, G pixel loss: =0.0429, adv loss: =0.0896]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.87it/s, epoch=44, D loss: =0.19, G pixel loss: =0.0428, adv loss: =0.0861] \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.87it/s, epoch=45, D loss: =0.184, G pixel loss: =0.0428, adv loss: =0.0887]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=46, D loss: =0.185, G pixel loss: =0.0427, adv loss: =0.0887]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.88it/s, epoch=47, D loss: =0.183, G pixel loss: =0.0427, adv loss: =0.0891]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=48, D loss: =0.183, G pixel loss: =0.0426, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=49, D loss: =0.188, G pixel loss: =0.0426, adv loss: =0.0867]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=50, D loss: =0.182, G pixel loss: =0.0426, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.87it/s, epoch=51, D loss: =0.188, G pixel loss: =0.0425, adv loss: =0.0872]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=52, D loss: =0.183, G pixel loss: =0.0425, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=53, D loss: =0.182, G pixel loss: =0.0425, adv loss: =0.0899]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=54, D loss: =0.193, G pixel loss: =0.0424, adv loss: =0.0848]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=55, D loss: =0.183, G pixel loss: =0.0424, adv loss: =0.0894]\n",
      "100%|██████████| 560/560 [04:42<00:00,  1.98it/s, epoch=56, D loss: =0.183, G pixel loss: =0.0423, adv loss: =0.0896]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=57, D loss: =0.188, G pixel loss: =0.0423, adv loss: =0.0872]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=58, D loss: =0.182, G pixel loss: =0.0423, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=59, D loss: =0.19, G pixel loss: =0.0422, adv loss: =0.0865] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=60, D loss: =0.188, G pixel loss: =0.0422, adv loss: =0.0863]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=61, D loss: =0.182, G pixel loss: =0.0422, adv loss: =0.0899]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=62, D loss: =0.182, G pixel loss: =0.0421, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=63, D loss: =0.185, G pixel loss: =0.0421, adv loss: =0.0883]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=64, D loss: =0.182, G pixel loss: =0.0421, adv loss: =0.0898]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.85it/s, epoch=65, D loss: =0.194, G pixel loss: =0.042, adv loss: =0.0876] \n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=66, D loss: =0.193, G pixel loss: =0.042, adv loss: =0.0823] \n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=67, D loss: =0.183, G pixel loss: =0.042, adv loss: =0.0888] \n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=68, D loss: =0.186, G pixel loss: =0.0419, adv loss: =0.0876]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=69, D loss: =0.182, G pixel loss: =0.0419, adv loss: =0.0896]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=70, D loss: =0.183, G pixel loss: =0.0419, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=71, D loss: =0.182, G pixel loss: =0.0418, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=72, D loss: =0.182, G pixel loss: =0.0418, adv loss: =0.0899]\n",
      "100%|██████████| 560/560 [05:08<00:00,  1.82it/s, epoch=73, D loss: =0.183, G pixel loss: =0.0418, adv loss: =0.0892]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=74, D loss: =0.182, G pixel loss: =0.0417, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=75, D loss: =0.182, G pixel loss: =0.0417, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=76, D loss: =0.184, G pixel loss: =0.0417, adv loss: =0.089] \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=77, D loss: =0.182, G pixel loss: =0.0416, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=78, D loss: =0.194, G pixel loss: =0.0416, adv loss: =0.0839]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=79, D loss: =0.182, G pixel loss: =0.0416, adv loss: =0.0894]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=80, D loss: =0.185, G pixel loss: =0.0416, adv loss: =0.0886]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=81, D loss: =0.182, G pixel loss: =0.0415, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=82, D loss: =0.182, G pixel loss: =0.0415, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=83, D loss: =0.191, G pixel loss: =0.0415, adv loss: =0.0855]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.82it/s, epoch=84, D loss: =0.182, G pixel loss: =0.0415, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=85, D loss: =0.187, G pixel loss: =0.0414, adv loss: =0.0872]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=86, D loss: =0.182, G pixel loss: =0.0414, adv loss: =0.0896]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=87, D loss: =0.182, G pixel loss: =0.0414, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=88, D loss: =0.184, G pixel loss: =0.0413, adv loss: =0.0891]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=89, D loss: =0.181, G pixel loss: =0.0413, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=90, D loss: =0.181, G pixel loss: =0.0413, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=91, D loss: =0.181, G pixel loss: =0.0413, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=92, D loss: =0.182, G pixel loss: =0.0412, adv loss: =0.0898]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=93, D loss: =0.181, G pixel loss: =0.0412, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=94, D loss: =0.181, G pixel loss: =0.0412, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=95, D loss: =0.181, G pixel loss: =0.0412, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=96, D loss: =0.182, G pixel loss: =0.0412, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=97, D loss: =0.181, G pixel loss: =0.0411, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.84it/s, epoch=98, D loss: =0.182, G pixel loss: =0.0411, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=99, D loss: =0.181, G pixel loss: =0.0411, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=100, D loss: =0.181, G pixel loss: =0.041, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=101, D loss: =0.181, G pixel loss: =0.041, adv loss: =0.09]   \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=102, D loss: =0.181, G pixel loss: =0.041, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=103, D loss: =0.181, G pixel loss: =0.041, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:08<00:00,  1.82it/s, epoch=104, D loss: =0.181, G pixel loss: =0.0409, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=105, D loss: =0.182, G pixel loss: =0.041, adv loss: =0.0898] \n",
      "100%|██████████| 560/560 [05:08<00:00,  1.82it/s, epoch=106, D loss: =0.181, G pixel loss: =0.0409, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=107, D loss: =0.181, G pixel loss: =0.0409, adv loss: =0.0905]\n",
      "100%|██████████| 560/560 [05:10<00:00,  1.81it/s, epoch=108, D loss: =0.181, G pixel loss: =0.0408, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=109, D loss: =0.181, G pixel loss: =0.0408, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=110, D loss: =0.183, G pixel loss: =0.0408, adv loss: =0.0893]\n",
      "100%|██████████| 560/560 [05:09<00:00,  1.81it/s, epoch=111, D loss: =0.181, G pixel loss: =0.0408, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=112, D loss: =0.182, G pixel loss: =0.0408, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=113, D loss: =0.181, G pixel loss: =0.0407, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=114, D loss: =0.181, G pixel loss: =0.0407, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=115, D loss: =0.181, G pixel loss: =0.0407, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=116, D loss: =0.181, G pixel loss: =0.0407, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=117, D loss: =0.182, G pixel loss: =0.0406, adv loss: =0.0896]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=118, D loss: =0.181, G pixel loss: =0.0407, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=119, D loss: =0.181, G pixel loss: =0.0406, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=120, D loss: =0.181, G pixel loss: =0.0406, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=121, D loss: =0.181, G pixel loss: =0.0406, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.84it/s, epoch=122, D loss: =0.181, G pixel loss: =0.0405, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=123, D loss: =0.181, G pixel loss: =0.0405, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=124, D loss: =0.181, G pixel loss: =0.0405, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=125, D loss: =0.181, G pixel loss: =0.0405, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=126, D loss: =0.183, G pixel loss: =0.0405, adv loss: =0.0892]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=127, D loss: =0.181, G pixel loss: =0.0405, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=128, D loss: =0.18, G pixel loss: =0.0404, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:09<00:00,  1.81it/s, epoch=129, D loss: =0.18, G pixel loss: =0.0404, adv loss: =0.0905] \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=130, D loss: =0.181, G pixel loss: =0.0404, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=131, D loss: =0.181, G pixel loss: =0.0403, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:08<00:00,  1.81it/s, epoch=132, D loss: =0.18, G pixel loss: =0.0403, adv loss: =0.0905] \n",
      "100%|██████████| 560/560 [05:07<00:00,  1.82it/s, epoch=133, D loss: =0.181, G pixel loss: =0.0403, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [04:57<00:00,  1.88it/s, epoch=134, D loss: =0.18, G pixel loss: =0.0403, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=135, D loss: =0.18, G pixel loss: =0.0403, adv loss: =0.0905] \n",
      "100%|██████████| 560/560 [05:06<00:00,  1.83it/s, epoch=136, D loss: =0.182, G pixel loss: =0.0403, adv loss: =0.0894]\n",
      "100%|██████████| 560/560 [05:10<00:00,  1.81it/s, epoch=137, D loss: =0.181, G pixel loss: =0.0402, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=138, D loss: =0.18, G pixel loss: =0.0402, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=139, D loss: =0.181, G pixel loss: =0.0402, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=140, D loss: =0.18, G pixel loss: =0.0402, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=141, D loss: =0.181, G pixel loss: =0.0401, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=142, D loss: =0.18, G pixel loss: =0.0401, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=143, D loss: =0.18, G pixel loss: =0.0401, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=144, D loss: =0.181, G pixel loss: =0.0401, adv loss: =0.0899]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=145, D loss: =0.18, G pixel loss: =0.0401, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=146, D loss: =0.181, G pixel loss: =0.0401, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=147, D loss: =0.18, G pixel loss: =0.0401, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=148, D loss: =0.18, G pixel loss: =0.04, adv loss: =0.0903]   \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=149, D loss: =0.181, G pixel loss: =0.04, adv loss: =0.0902]  \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=150, D loss: =0.181, G pixel loss: =0.04, adv loss: =0.0904]  \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=151, D loss: =0.18, G pixel loss: =0.04, adv loss: =0.0904]   \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=152, D loss: =0.18, G pixel loss: =0.04, adv loss: =0.0903]  \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=153, D loss: =0.18, G pixel loss: =0.0399, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=154, D loss: =0.182, G pixel loss: =0.0399, adv loss: =0.0898]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=155, D loss: =0.18, G pixel loss: =0.0399, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=156, D loss: =0.181, G pixel loss: =0.0399, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=157, D loss: =0.18, G pixel loss: =0.0399, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=158, D loss: =0.181, G pixel loss: =0.0398, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.87it/s, epoch=159, D loss: =0.181, G pixel loss: =0.0398, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=160, D loss: =0.18, G pixel loss: =0.0398, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=161, D loss: =0.18, G pixel loss: =0.0398, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=162, D loss: =0.18, G pixel loss: =0.0398, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=163, D loss: =0.18, G pixel loss: =0.0398, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=164, D loss: =0.182, G pixel loss: =0.0398, adv loss: =0.0894]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=165, D loss: =0.18, G pixel loss: =0.0398, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=166, D loss: =0.181, G pixel loss: =0.0397, adv loss: =0.09]  \n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=167, D loss: =0.18, G pixel loss: =0.0397, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=168, D loss: =0.18, G pixel loss: =0.0397, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:05<00:00,  1.83it/s, epoch=169, D loss: =0.181, G pixel loss: =0.0397, adv loss: =0.0902]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=170, D loss: =0.18, G pixel loss: =0.0396, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=171, D loss: =0.18, G pixel loss: =0.0396, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=172, D loss: =0.18, G pixel loss: =0.0396, adv loss: =0.0902] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=173, D loss: =0.18, G pixel loss: =0.0396, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=174, D loss: =0.181, G pixel loss: =0.0396, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=175, D loss: =0.18, G pixel loss: =0.0395, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.88it/s, epoch=176, D loss: =0.18, G pixel loss: =0.0396, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [04:57<00:00,  1.88it/s, epoch=177, D loss: =0.181, G pixel loss: =0.0395, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.88it/s, epoch=178, D loss: =0.18, G pixel loss: =0.0395, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:04<00:00,  1.84it/s, epoch=179, D loss: =0.181, G pixel loss: =0.0395, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:03<00:00,  1.84it/s, epoch=180, D loss: =0.18, G pixel loss: =0.0395, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=181, D loss: =0.18, G pixel loss: =0.0395, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=182, D loss: =0.181, G pixel loss: =0.0395, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [04:57<00:00,  1.89it/s, epoch=183, D loss: =0.18, G pixel loss: =0.0394, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=184, D loss: =0.18, G pixel loss: =0.0394, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [04:55<00:00,  1.90it/s, epoch=185, D loss: =0.181, G pixel loss: =0.0394, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=186, D loss: =0.18, G pixel loss: =0.0394, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:02<00:00,  1.85it/s, epoch=187, D loss: =0.18, G pixel loss: =0.0394, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [04:58<00:00,  1.87it/s, epoch=188, D loss: =0.182, G pixel loss: =0.0394, adv loss: =0.0897]\n",
      "100%|██████████| 560/560 [04:57<00:00,  1.88it/s, epoch=189, D loss: =0.18, G pixel loss: =0.0394, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=190, D loss: =0.181, G pixel loss: =0.0393, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=191, D loss: =0.18, G pixel loss: =0.0393, adv loss: =0.0904] \n",
      "100%|██████████| 560/560 [05:03<00:00,  1.85it/s, epoch=192, D loss: =0.181, G pixel loss: =0.0393, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=193, D loss: =0.18, G pixel loss: =0.0393, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [04:56<00:00,  1.89it/s, epoch=194, D loss: =0.18, G pixel loss: =0.0393, adv loss: =0.0903]\n",
      "100%|██████████| 560/560 [05:01<00:00,  1.86it/s, epoch=195, D loss: =0.181, G pixel loss: =0.0393, adv loss: =0.0901]\n",
      "100%|██████████| 560/560 [04:59<00:00,  1.87it/s, epoch=196, D loss: =0.18, G pixel loss: =0.0392, adv loss: =0.0903] \n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=197, D loss: =0.181, G pixel loss: =0.0392, adv loss: =0.0904]\n",
      "100%|██████████| 560/560 [05:00<00:00,  1.86it/s, epoch=198, D loss: =0.18, G pixel loss: =0.0392, adv loss: =0.0903]\n",
      " 53%|█████▎    | 299/560 [02:42<02:21,  1.84it/s, epoch=199, D loss: =0.18, G pixel loss: =0.0391, adv loss: =0.0903]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradient Accumulation을 사용하여 매 N 스텝마다 가중치 업데이트\u001b[39;00m\n\u001b[1;32m     29\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss_G)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer_G\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     34\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/amp/grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_pixel = 50\n",
    "lambda1=1.02\n",
    "for epoch in range(params['epochs']):\n",
    "    total_loss_D = 0\n",
    "    total_loss_pixel = 0\n",
    "    total_loss_GAN = 0\n",
    "    steps = 0\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    optimizer_D.zero_grad()\n",
    "    \n",
    "    with tqdm(dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "        for i, (RGB_image, L_image) in enumerate(tqdmDataLoader):\n",
    "            # 모델의 입력 데이터 로드\n",
    "            real_A = L_image.to(device)  # Grayscale\n",
    "            real_B = RGB_image.to(device)  # Color\n",
    "\n",
    "            real = torch.FloatTensor(real_A.size(0), 1, 32, 32).fill_(0.9).to(device)  # 진짜\n",
    "            fake = torch.FloatTensor(real_A.size(0), 1, 32, 32).fill_(0.0).to(device)  # 가짜\n",
    "\n",
    "            # Mixed Precision Training으로 Generator 학습\n",
    "            with amp.autocast():\n",
    "                fake_B = generator(real_A)\n",
    "                loss_GAN = criterion_GAN(discriminator(fake_B, real_A), real)\n",
    "                loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "                loss_G = loss_GAN + (lambda_pixel*lambda1**epoch) * loss_pixel\n",
    "\n",
    "            # Gradient Accumulation을 사용하여 매 N 스텝마다 가중치 업데이트\n",
    "            scaler.scale(loss_G).backward()\n",
    "\n",
    "            \n",
    "            scaler.step(optimizer_G)\n",
    "            scaler.update()\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Discriminator 학습\n",
    "            with amp.autocast():\n",
    "                loss_real = criterion_GAN(discriminator(real_B, real_A), real)\n",
    "                loss_fake = criterion_GAN(discriminator(fake_B.detach(), real_A), fake)\n",
    "                loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "            scaler.scale(loss_D).backward()\n",
    "\n",
    "            if (i + 1) % params['gradient_accumulation_steps'] == 0:\n",
    "                scaler.step(optimizer_D)\n",
    "                scaler.update()\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "            total_loss_D += loss_D.item()\n",
    "            total_loss_pixel += loss_pixel.item()\n",
    "            total_loss_GAN += loss_GAN.item()\n",
    "            steps += 1\n",
    "\n",
    "            tqdmDataLoader.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"D loss: \": total_loss_D / steps,\n",
    "                    \"G pixel loss: \": total_loss_pixel / steps,\n",
    "                    \"adv loss: \": total_loss_GAN / steps,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # 이미지 샘플 저장\n",
    "    imgs = next(iter(dataloader))\n",
    "    real_A = (imgs[1].to(device) + 1) / 2\n",
    "    real_B = (imgs[0].to(device) + 1) / 2\n",
    "    fake_B = (generator(real_A) + 1) / 2\n",
    "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
    "    to_pil_image(img_sample[0]).save(f'../../result/colorization/pix2pix/{epoch}.png')\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save(generator.state_dict(), f\"../../model/colorization/pix2pix/Pix2Pix_Generator_for_Colorization_{epoch}.pt\")\n",
    "    torch.save(discriminator.state_dict(), f\"../../model/colorization/pix2pix/Pix2Pix_Discriminator_for_Colorization_{epoch}.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
