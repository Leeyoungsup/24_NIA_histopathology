{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used:\t8\n",
      "Device:\t\tcuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_model_summary as tms\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torchmetrics\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",0)\n",
    "print(f\"Device:\\t\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['normal','abnormal']\n",
    "params={'image_size':512,\n",
    "        'lr':2e-5,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':50,\n",
    "        'n_classes':2,\n",
    "        'inch':3,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test_0.csv: 100%|██████████| 20/20 [00:04<00:00,  4.07it/s]\n",
      "Processing test_1.csv: 100%|██████████| 20/20 [00:02<00:00,  7.90it/s]\n",
      "Processing test_2.csv: 100%|██████████| 20/20 [00:03<00:00,  5.60it/s]\n",
      "Processing test_3.csv: 100%|██████████| 20/20 [00:02<00:00,  6.80it/s]\n",
      "Processing test_4.csv: 100%|██████████| 20/20 [00:02<00:00,  6.73it/s]\n",
      "Processing test_5.csv: 100%|██████████| 20/20 [00:02<00:00,  7.75it/s]\n",
      "Processing test_6.csv: 100%|██████████| 20/20 [00:03<00:00,  6.02it/s]\n",
      "Processing test_7.csv: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s]\n",
      "Processing test_8.csv: 100%|██████████| 20/20 [00:02<00:00,  6.75it/s]\n",
      "Processing test_9.csv: 100%|██████████| 20/20 [00:03<00:00,  5.26it/s]\n",
      "Processing test_10.csv: 100%|██████████| 20/20 [00:03<00:00,  5.32it/s]\n",
      "Processing test_11.csv: 100%|██████████| 20/20 [00:03<00:00,  6.66it/s]\n",
      "Processing test_12.csv: 100%|██████████| 20/20 [00:03<00:00,  6.39it/s]\n",
      "Processing test_13.csv: 100%|██████████| 20/20 [00:03<00:00,  6.53it/s]\n",
      "Processing test_14.csv: 100%|██████████| 20/20 [00:02<00:00,  6.80it/s]\n",
      "Processing test_15.csv: 100%|██████████| 20/20 [00:04<00:00,  4.98it/s]\n",
      "Processing test_16.csv: 100%|██████████| 20/20 [00:03<00:00,  6.07it/s]\n",
      "Processing test_17.csv: 100%|██████████| 20/20 [00:03<00:00,  5.40it/s]\n",
      "Processing test_18.csv: 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n",
      "Processing test_19.csv: 100%|██████████| 20/20 [00:03<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self, params, images, labels):\n",
    "        self.images = images\n",
    "        self.args = params\n",
    "        self.labels = labels\n",
    "        \n",
    "    def trans(self, image):\n",
    "        if random.random() > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "        if random.random() > 0.5:\n",
    "            image = transforms.functional.vflip(image)\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        image = self.trans(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "# DataLoader 딕셔너리를 생성하여 각 CSV 파일에 대한 DataLoader를 저장\n",
    "dataloaders = {}\n",
    "csv_folder = '../../data/usefulness/breast/'  # CSV 파일이 저장된 폴더 경로\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.startswith('test_') and f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(csv_folder, csv_file)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 이미지 경로와 레이블을 리스트로 추출\n",
    "    image_paths = df['image'].tolist()\n",
    "    image_labels = df['label'].tolist()\n",
    "    \n",
    "    # 이미지 데이터를 텐서로 변환\n",
    "    test_images = torch.zeros((len(image_paths), params['inch'], params['image_size'], params['image_size']))\n",
    "    for i in tqdm(range(len(image_paths)), desc=f\"Processing {csv_file}\"):\n",
    "        test_images[i] = trans(Image.open(image_paths[i]).convert('RGB').resize((params['image_size'], params['image_size'])))\n",
    "    \n",
    "    # 레이블을 one-hot 인코딩하여 텐서로 변환\n",
    "    test_labels = torch.tensor(image_labels)\n",
    "    test_labels = torch.nn.functional.one_hot(test_labels).to(torch.int64)\n",
    "    \n",
    "    # CustomDataset 및 DataLoader 생성\n",
    "    test_dataset = CustomDataset(params, test_images, test_labels)\n",
    "    dataloaders[csv_file] = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "# 각 DataLoader는 dataloaders 딕셔너리에서 접근 가능\n",
    "# 예를 들어, test_0.csv에 대한 DataLoader는 dataloaders['test_0.csv']로 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('tf_efficientnetv2_s', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(custom_model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size, 2048, 1, 1)\n",
    "        \n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, _BatchNorm):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "            \n",
    "import transformers\n",
    "\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "raw_model = custom_model(2,1280,Feature_Extractor)\n",
    "raw_model = raw_model.to(device)\n",
    "source_model = custom_model(2,1280,Feature_Extractor)\n",
    "source_model = source_model.to(device)\n",
    "base_optimizer = torch.optim.SGD\n",
    "# optimizer = SAM(model.parameters(), base_optimizer, lr=params['lr'], momentum=0.9)\n",
    "raw_model.load_state_dict(torch.load('../../model/usefulness/breast/raw_usefulness_check.pt',map_location=device))\n",
    "source_model.load_state_dict(torch.load('../../model/usefulness/breast/source_usefulness_check.pt',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "raw test_0.csv:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "raw test_0.csv: 100%|██████████| 20/20 [00:01<00:00, 12.89it/s]\n",
      "source test_0.csv: 100%|██████████| 20/20 [00:01<00:00, 18.71it/s]\n",
      "raw test_1.csv: 100%|██████████| 20/20 [00:00<00:00, 33.62it/s]\n",
      "source test_1.csv: 100%|██████████| 20/20 [00:00<00:00, 21.49it/s]\n",
      "raw test_2.csv: 100%|██████████| 20/20 [00:01<00:00, 19.22it/s]\n",
      "source test_2.csv: 100%|██████████| 20/20 [00:00<00:00, 28.44it/s]\n",
      "raw test_3.csv: 100%|██████████| 20/20 [00:00<00:00, 22.87it/s]\n",
      "source test_3.csv: 100%|██████████| 20/20 [00:01<00:00, 17.98it/s]\n",
      "raw test_4.csv: 100%|██████████| 20/20 [00:00<00:00, 20.98it/s]\n",
      "source test_4.csv: 100%|██████████| 20/20 [00:00<00:00, 28.20it/s]\n",
      "raw test_5.csv: 100%|██████████| 20/20 [00:01<00:00, 18.58it/s]\n",
      "source test_5.csv: 100%|██████████| 20/20 [00:01<00:00, 18.91it/s]\n",
      "raw test_6.csv: 100%|██████████| 20/20 [00:00<00:00, 28.86it/s]\n",
      "source test_6.csv: 100%|██████████| 20/20 [00:01<00:00, 17.51it/s]\n",
      "raw test_7.csv: 100%|██████████| 20/20 [00:01<00:00, 18.06it/s]\n",
      "source test_7.csv: 100%|██████████| 20/20 [00:00<00:00, 36.42it/s]\n",
      "raw test_8.csv: 100%|██████████| 20/20 [00:00<00:00, 29.58it/s]\n",
      "source test_8.csv: 100%|██████████| 20/20 [00:01<00:00, 19.06it/s]\n",
      "raw test_9.csv: 100%|██████████| 20/20 [00:01<00:00, 17.38it/s]\n",
      "source test_9.csv: 100%|██████████| 20/20 [00:00<00:00, 38.36it/s]\n",
      "raw test_10.csv: 100%|██████████| 20/20 [00:01<00:00, 15.89it/s]\n",
      "source test_10.csv: 100%|██████████| 20/20 [00:01<00:00, 19.87it/s]\n",
      "raw test_11.csv: 100%|██████████| 20/20 [00:00<00:00, 30.77it/s]\n",
      "source test_11.csv: 100%|██████████| 20/20 [00:00<00:00, 31.35it/s]\n",
      "raw test_12.csv: 100%|██████████| 20/20 [00:00<00:00, 23.57it/s]\n",
      "source test_12.csv: 100%|██████████| 20/20 [00:00<00:00, 27.39it/s]\n",
      "raw test_13.csv: 100%|██████████| 20/20 [00:00<00:00, 36.53it/s]\n",
      "source test_13.csv: 100%|██████████| 20/20 [00:00<00:00, 26.12it/s]\n",
      "raw test_14.csv: 100%|██████████| 20/20 [00:00<00:00, 24.73it/s]\n",
      "source test_14.csv: 100%|██████████| 20/20 [00:01<00:00, 19.31it/s]\n",
      "raw test_15.csv: 100%|██████████| 20/20 [00:00<00:00, 50.03it/s]\n",
      "source test_15.csv: 100%|██████████| 20/20 [00:00<00:00, 42.92it/s]\n",
      "raw test_16.csv: 100%|██████████| 20/20 [00:00<00:00, 26.88it/s]\n",
      "source test_16.csv: 100%|██████████| 20/20 [00:00<00:00, 33.15it/s]\n",
      "raw test_17.csv: 100%|██████████| 20/20 [00:00<00:00, 51.27it/s]\n",
      "source test_17.csv: 100%|██████████| 20/20 [00:00<00:00, 30.72it/s]\n",
      "raw test_18.csv: 100%|██████████| 20/20 [00:00<00:00, 32.77it/s]\n",
      "source test_18.csv: 100%|██████████| 20/20 [00:00<00:00, 32.56it/s]\n",
      "raw test_19.csv: 100%|██████████| 20/20 [00:00<00:00, 27.87it/s]\n",
      "source test_19.csv: 100%|██████████| 20/20 [00:00<00:00, 29.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores saved to f1_scores.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize F1 score metric for binary classification\n",
    "f1_metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=2).to(device)\n",
    "\n",
    "# Function to evaluate a model on a given DataLoader\n",
    "# Function to evaluate a model on a given DataLoader\n",
    "def evaluate_model_manual_f1(model, dataloader,csv_file):\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize counts\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=csv_file):\n",
    "            images = images.to(device)\n",
    "            labels = labels.argmax(dim=1).to(device)  # Convert one-hot encoded labels to class indices\n",
    "            logits = model(images)\n",
    "            preds = torch.argmax(logits, dim=1)  # Get predicted class indices\n",
    "            \n",
    "            # Calculate TP, TN, FP, FN\n",
    "            tp += ((preds == 1) & (labels == 1)).sum().item()\n",
    "            tn += ((preds == 0) & (labels == 0)).sum().item()\n",
    "            fp += ((preds == 1) & (labels == 0)).sum().item()\n",
    "            fn += ((preds == 0) & (labels == 1)).sum().item()\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1_score\n",
    "# Load each test set and evaluate with both models\n",
    "# Dictionary to store F1 scores for each model on each test set\n",
    "f1_scores = {'raw_model': {}, 'source_model': {}}\n",
    "\n",
    "# Evaluate both raw_model and source_model on each test set DataLoader\n",
    "for csv_file, dataloader in dataloaders.items():\n",
    "    # Evaluate raw_model\n",
    "    f1_raw = evaluate_model_manual_f1(raw_model, dataloader,'raw '+csv_file)\n",
    "    f1_scores['raw_model'][csv_file] = f1_raw\n",
    "    \n",
    "    # Evaluate source_model\n",
    "    f1_source = evaluate_model_manual_f1(source_model, dataloader,'source '+csv_file)\n",
    "    f1_scores['source_model'][csv_file] = f1_source\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier CSV export\n",
    "f1_scores_df = pd.DataFrame(f1_scores)\n",
    "\n",
    "# Save to CSV\n",
    "f1_scores_df.to_csv(\"../../result/usefulness/breast/f1_scores.csv\", index_label=\"Test Set\")\n",
    "\n",
    "print(\"F1 scores saved to f1_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6235,  0.3725,  0.0196,  ...,  0.7725,  0.8275,  0.7647],\n",
       "          [-0.6863,  0.3020,  0.3569,  ...,  0.8510,  0.7725,  0.7804],\n",
       "          [-0.7020,  0.1294,  0.2392,  ...,  0.8275,  0.8510,  0.8588],\n",
       "          ...,\n",
       "          [-0.1059,  0.7725,  0.7725,  ...,  0.5451,  0.3569,  0.0275],\n",
       "          [-0.0039,  0.8588,  0.8039,  ...,  0.5608,  0.3255,  0.3020],\n",
       "          [-0.0824,  0.7804,  0.8431,  ...,  0.5765,  0.5765,  0.2157]],\n",
       " \n",
       "         [[-0.7490,  0.0980, -0.4353,  ...,  0.7333,  0.7725,  0.7098],\n",
       "          [-0.8588, -0.0431, -0.1451,  ...,  0.7804,  0.7020,  0.7020],\n",
       "          [-0.9216, -0.2627, -0.3020,  ...,  0.7176,  0.7490,  0.7569],\n",
       "          ...,\n",
       "          [-0.1137,  0.7098,  0.6706,  ..., -0.1451, -0.3098, -0.6078],\n",
       "          [-0.0118,  0.7725,  0.6549,  ..., -0.1529, -0.3647, -0.3882],\n",
       "          [-0.0980,  0.6863,  0.6706,  ..., -0.1529, -0.1373, -0.4980]],\n",
       " \n",
       "         [[-0.6314,  0.3569, -0.0275,  ...,  0.7804,  0.8275,  0.7647],\n",
       "          [-0.7412,  0.2471,  0.2863,  ...,  0.8588,  0.7882,  0.7882],\n",
       "          [-0.7882,  0.0431,  0.1373,  ...,  0.8431,  0.8824,  0.8824],\n",
       "          ...,\n",
       "          [-0.0745,  0.7804,  0.8039,  ...,  0.3882,  0.2157, -0.0902],\n",
       "          [ 0.0275,  0.8667,  0.8196,  ...,  0.3882,  0.1686,  0.1451],\n",
       "          [-0.0431,  0.7961,  0.8667,  ...,  0.4039,  0.4118,  0.0510]]]),\n",
       " tensor([1, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
