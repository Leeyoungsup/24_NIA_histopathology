{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=4\n",
    "img_size=1024\n",
    "tf = ToTensor()\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/449 [00:00<00:34, 12.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train))):\n\u001b[1;32m     13\u001b[0m     train_image[i] \u001b[38;5;241m=\u001b[39m tf(np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(X_train[i])\u001b[38;5;241m.\u001b[39mresize((img_size, img_size))))\n\u001b[0;32m---> 14\u001b[0m     train_mask[i]\u001b[38;5;241m=\u001b[39mtf(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test))):\n\u001b[1;32m     16\u001b[0m     test_image[i] \u001b[38;5;241m=\u001b[39m tf(np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(X_test[i])\u001b[38;5;241m.\u001b[39mresize((img_size, img_size))))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/numpy/lib/format.py:802\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _isfileobj(fp):\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_path='../../data/area_segmentation/BRDC/image/'\n",
    "img_list=glob(img_path+'*.jpeg')\n",
    "mask_list=[i.replace('/image','/mask') for i in img_list]\n",
    "mask_list=[i.replace('.jpeg','.npy') for i in mask_list]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(img_list, mask_list, test_size=0.2, random_state=321)\n",
    "\n",
    "test_image=torch.zeros((len(X_test),3,img_size,img_size))\n",
    "test_mask=torch.zeros((len(Y_test),5,img_size,img_size),dtype=torch.uint8)    \n",
    "train_image=torch.zeros((len(X_train),3,img_size,img_size))\n",
    "train_mask=torch.zeros((len(Y_train),5,img_size,img_size),dtype=torch.uint8)\n",
    "\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    train_image[i] = tf(np.array(Image.open(X_train[i]).resize((img_size, img_size))))\n",
    "    train_mask[i]=tf(np.load(Y_train[i]))\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    test_image[i] = tf(np.array(Image.open(X_test[i]).resize((img_size, img_size))))\n",
    "    test_mask[i]=tf(np.load(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.img_path[idx]\n",
    "        label_path =  self.label[idx]\n",
    "        return image_path, label_path\n",
    "    \n",
    "train_dataset = CustomDataset(train_image, train_mask)\n",
    "\n",
    "test_dataset = CustomDataset(test_image, test_mask)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=smp.UnetPlusPlus('efficientnet-b5', in_channels=3, classes=5).to(device)\n",
    "summary(model,(batch_size,3,img_size,img_size))\n",
    "def dice_loss(pred, target, num_classes=4):\n",
    "    # Apply softmax to predictions\n",
    "    pred_softmax = F.sigmoid(pred)\n",
    "    \n",
    "    # Ensure the target tensor is in float type\n",
    "    target = target.float()\n",
    "    dice_loss=torch.zeros(len(target))\n",
    "    for i in range(len(target)):\n",
    "        # Calculate the Dice coefficient for each class\n",
    "        intersection = (pred_softmax[i] * target[i]).sum(dim=(1, 2))\n",
    "        union = pred_softmax[i].sum(dim=(1,2)) + target[i].sum(dim=(1,2))\n",
    "        \n",
    "        dice_coefficient = 2. * intersection / (union + 1e-5)  # Adding a small epsilon to avoid division by zero\n",
    "        \n",
    "        # Calculate the Dice loss\n",
    "        dice_loss[i] = 1 - dice_coefficient.mean()\n",
    "    \n",
    "    return dice_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/224 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/300 Step: 225 dice_loss : 0.8177 dice_score: 0.1823: 100%|██████████| 224/224 [01:13<00:00,  3.05it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m         train\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m300\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dice_loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39mcount\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dice_score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mrunning_loss\u001b[38;5;241m/\u001b[39mcount\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m     train_loss_list\u001b[38;5;241m.\u001b[39mappend((running_loss\u001b[38;5;241m/\u001b[39mcount))\n\u001b[0;32m---> 31\u001b[0m     train_acc_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43m(\u001b[49m\u001b[43macc_loss\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#test\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     val\u001b[38;5;241m=\u001b[39mtqdm(test_dataloader)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "MIN_loss=5000\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4)\n",
    "metrics = defaultdict(float)\n",
    "for epoch in range(300):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = dice_loss(predict, y) # cost 구함\n",
    "        acc=1-cost.item()\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        y = y.to('cpu')\n",
    "\n",
    "        x=x.to('cpu')\n",
    "        train.set_description(f\"epoch: {epoch+1}/{300} Step: {count+1} dice_loss : {running_loss/count:.4f} dice_score: {1-running_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count))\n",
    "#test\n",
    "    val=tqdm(test_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            cost = dice_loss(predict, y) # cost 구함\n",
    "            acc=1-cost.item()\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            y = y.to('cpu')\n",
    "            x=x.to('cpu')\n",
    "            val.set_description(f\"test epoch: {epoch+1}/{300} Step: {count+1} dice_loss : {val_running_loss/count:.4f}  dice_score: {1-val_running_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count))\n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        torch.save(model.state_dict(), '../../model/areaSeg/UnetPlusPlus_callback.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "        \n",
    "    if epoch%50==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='test_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='test_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.title('loss_graph')\n",
    "plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "plt.plot(np.arange(epoch+1),val_loss_list,label='test_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim([0, 1]) \n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)  \n",
    "plt.title('acc_graph')\n",
    "plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "plt.plot(np.arange(epoch+1),val_acc_list,label='test_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([0, 1]) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('batch size= 2')\n",
    "print('image size= 1024,1024')\n",
    "print('learning rate= 0.0001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
